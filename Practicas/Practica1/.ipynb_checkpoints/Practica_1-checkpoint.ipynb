{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "758d91fe",
   "metadata": {},
   "source": [
    "Práctica 1 Análisis exploratorio\n",
    "Utilizando el dataset de los pagos de la UANL (https://github.com/ppGodel/data_mining/blob/main/csv/typed_uanl.csv) van a realizar un análisis exploratorio. Hay que crear una script donde realices lo siguiente:\n",
    " \n",
    "1.\tIdentificar las entidades (que es lo que puede ser sujeto de estudio) del conjunto. agrégalo como un comentario en tu script.\n",
    "2.\tObtener las estadísticas (descriptiva) de cada entidad (min, max, avg, std)\n",
    "3.\tHacer agrupaciones por las entidades y sacar estadísticas de las agrupaciones.\n",
    "4.\tCrear imágenes de estas estadísticas, ya sean histogramas, graficas de pastel, etc., al menos 3 graficas diferentes, Hay que crear muchas imágenes, así que creen ciclos y recorran las agrupaciones. \n",
    "5.\tDe alguna de las agrupaciones, hacer una prueba ANOVA, para ver si hay diferencias entre los elementos. recordando, hay que probar que las muestras son o no normales. sí son normales anova para la prueba y t-student para saber quién es el diferente. Si la muestra no es normal, prueba con kruskall-wallis y tukey para saber quién es el diferente.  \n",
    "Realiza un reporte escrito de tus hallazgos. No quiero una descripción de que hiciste, sino de que encontraste, cosas que no sabias y supiste una vez que comenzaste a analizar los datos, cuenta que cosas guiaron tu atención para encontrar información que consideras significativa, y muestra esos hallazgos con imágenes, así que prepara tus imágenes para que alguien las vea.\n",
    "Hay que crear un repositorio de github/gitlab con 2 carpetas en la raíz del repositorio: Reportes y Practicas. En Reporte estará el reporte en formato PDF con el nombre Practica#.pdf donde # es el numero de la practica al que corresponde. En  la carpeta de prácticas por cada practica habrá una carpeta de nombre Practica# donde estará todo el código, imágenes, conjuntos de datos que usaste para la práctica.\n",
    " \n",
    "Link para pasarme tu repositorio:\n",
    "https://forms.office.com/r/YuvnZHMif0\n",
    "La fecha límite para subir el reporte y el código a git es el domingo 30 de junio. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ba551c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dde56a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Identificar las entidades\n",
    "# Entidades: Nombre (empleado), Sueldo Neto, Dependencia, Fecha, Tipo\n",
    "\n",
    "# Cargar los datos desde el archivo CSV\n",
    "df = pd.read_csv('csv/typed_uanl.csv')\n",
    "\n",
    "# Convertir la columna 'Fecha' a tipo datetime\n",
    "df['Fecha'] = pd.to_datetime(df['Fecha'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54309c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                Nombre    Sueldo Neto             dependencia  \\\n",
      "count                           636201  636201.000000                  636201   \n",
      "unique                           21034            NaN                     152   \n",
      "top     JUAN ANTONIO RAMIREZ HERNANDEZ            NaN  HOSPITAL UNIVERSITARIO   \n",
      "freq                                97            NaN                  105549   \n",
      "first                              NaN            NaN                     NaN   \n",
      "last                               NaN            NaN                     NaN   \n",
      "mean                               NaN   14241.682401                     NaN   \n",
      "std                                NaN    9578.442311                     NaN   \n",
      "min                                NaN     175.410000                     NaN   \n",
      "25%                                NaN    8007.660000                     NaN   \n",
      "50%                                NaN   11426.500000                     NaN   \n",
      "75%                                NaN   17654.630000                     NaN   \n",
      "max                                NaN  147051.590000                     NaN   \n",
      "\n",
      "                      Fecha      Tipo  \n",
      "count                636201    636201  \n",
      "unique                   48         6  \n",
      "top     2020-12-01 00:00:00  FACULTAD  \n",
      "freq                  14890    274527  \n",
      "first   2019-12-01 00:00:00       NaN  \n",
      "last    2024-01-01 00:00:00       NaN  \n",
      "mean                    NaN       NaN  \n",
      "std                     NaN       NaN  \n",
      "min                     NaN       NaN  \n",
      "25%                     NaN       NaN  \n",
      "50%                     NaN       NaN  \n",
      "75%                     NaN       NaN  \n",
      "max                     NaN       NaN  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_19404\\182094452.py:2: FutureWarning: Treating datetime data as categorical rather than numeric in `.describe` is deprecated and will be removed in a future version of pandas. Specify `datetime_is_numeric=True` to silence this warning and adopt the future behavior now.\n",
      "  estadisticas_descriptivas = df.describe(include='all')\n"
     ]
    }
   ],
   "source": [
    "# 2. Obtener las estadísticas descriptivas de cada entidad\n",
    "estadisticas_descriptivas = df.describe(include='all')\n",
    "print(estadisticas_descriptivas)\n",
    "\n",
    "# Guardar las estadísticas descriptivas en un archivo CSV\n",
    "estadisticas_descriptivas.to_csv('resultados/estadisticas_descriptivas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47892cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estadísticas descriptivas por dependencia guardadas en 'estadisticas_dependencia.csv'.\n",
      "Estadísticas descriptivas por tipo de dependencia guardadas en 'estadisticas_tipo_dependencia.csv'.\n",
      "Estadísticas descriptivas por fecha guardadas en 'estadisticas_fecha.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Función para obtener estadísticas descriptivas con percentiles adicionales y otros cálculos\n",
    "def obtener_estadisticas_descriptivas(df, entidad):\n",
    "    estadisticas = df.groupby(entidad)['Sueldo Neto'].describe()\n",
    "    estadisticas['25%'] = df.groupby(entidad)['Sueldo Neto'].quantile(0.25)\n",
    "    estadisticas['50%'] = df.groupby(entidad)['Sueldo Neto'].quantile(0.50)\n",
    "    estadisticas['75%'] = df.groupby(entidad)['Sueldo Neto'].quantile(0.75)\n",
    "    estadisticas['Rango'] = estadisticas['max'] - estadisticas['min']\n",
    "    estadisticas['Varianza'] = df.groupby(entidad)['Sueldo Neto'].var()\n",
    "    estadisticas['Desviación_Estándar'] = estadisticas['std']\n",
    "    estadisticas['Coeficiente_de_Variación'] = estadisticas['std'] / estadisticas['mean']\n",
    "    estadisticas['Número_de_Clases'] = 1 + 3.322 * np.log10(estadisticas['count'])\n",
    "    estadisticas['Ancho_de_Clase'] = estadisticas['Rango'] / estadisticas['Número_de_Clases']\n",
    "    return estadisticas\n",
    "\n",
    "# Función para guardar las estadísticas en un archivo CSV\n",
    "def guardar_estadisticas_csv(estadisticas, nombre_archivo):\n",
    "    estadisticas.to_csv(nombre_archivo)\n",
    "\n",
    "# Estadísticas descriptivas por dependencia\n",
    "estadisticas_dependencia = obtener_estadisticas_descriptivas(df, 'dependencia')\n",
    "guardar_estadisticas_csv(estadisticas_dependencia, 'resultados/estadisticas_dependencia.csv')\n",
    "print(\"Estadísticas descriptivas por dependencia guardadas en 'estadisticas_dependencia.csv'.\")\n",
    "\n",
    "# Estadísticas descriptivas por tipo de dependencia\n",
    "estadisticas_tipo = obtener_estadisticas_descriptivas(df, 'Tipo')\n",
    "guardar_estadisticas_csv(estadisticas_tipo, 'resultados/estadisticas_tipo_dependencia.csv')\n",
    "print(\"Estadísticas descriptivas por tipo de dependencia guardadas en 'estadisticas_tipo_dependencia.csv'.\")\n",
    "\n",
    "# Estadísticas descriptivas por empleado\n",
    "# estadisticas_empleado = obtener_estadisticas_descriptivas(df, 'Nombre')\n",
    "# guardar_estadisticas_csv(estadisticas_empleado, 'estadisticas_empleado.csv')\n",
    "# print(\"Estadísticas descriptivas por empleado guardadas en 'estadisticas_empleado.csv'.\")\n",
    "\n",
    "# Estadísticas descriptivas por fecha\n",
    "estadisticas_fecha = obtener_estadisticas_descriptivas(df, 'Fecha')\n",
    "guardar_estadisticas_csv(estadisticas_fecha, 'resultados/estadisticas_fecha.csv')\n",
    "print(\"Estadísticas descriptivas por fecha guardadas en 'estadisticas_fecha.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba70faae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82cb4a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\seaborn\\matrix.py:198: RuntimeWarning: All-NaN slice encountered\n",
      "  vmin = np.nanmin(calc_data)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\seaborn\\matrix.py:203: RuntimeWarning: All-NaN slice encountered\n",
      "  vmax = np.nanmax(calc_data)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\seaborn\\matrix.py:198: RuntimeWarning: All-NaN slice encountered\n",
      "  vmin = np.nanmin(calc_data)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\seaborn\\matrix.py:203: RuntimeWarning: All-NaN slice encountered\n",
      "  vmax = np.nanmax(calc_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gráficos generados exitosamente.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "# Crear columnas de año y mes\n",
    "df['Año'] = df['Fecha'].dt.year\n",
    "df['Mes'] = df['Fecha'].dt.month\n",
    "\n",
    "# Estadísticas generales por tipo\n",
    "tipo_stats = df.groupby('Tipo')['Sueldo Neto'].describe()\n",
    "tipo_stats = tipo_stats.sort_values(by='count', ascending=False)\n",
    "\n",
    "# Estadísticas por año y mes\n",
    "sueldo_por_mes = df.groupby(['Año', 'Mes'])['Sueldo Neto'].sum().unstack()\n",
    "sueldo_promedio_por_mes = df.groupby(['Año', 'Mes'])['Sueldo Neto'].mean().unstack()\n",
    "\n",
    "# Gráficos de líneas para sueldos totales por mes a lo largo de los años\n",
    "plt.figure(figsize=(14, 7))\n",
    "ax = sueldo_por_mes.T.plot(kind='line', title='Suma de Sueldos por Mes')\n",
    "ax.set_xlabel('Mes')\n",
    "ax.set_ylabel('Sueldo Total')\n",
    "ax.xaxis.set_major_locator(ticker.MaxNLocator(integer=True))\n",
    "ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x)))\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/001-suma_sueldos_por_mes.png')\n",
    "plt.close()\n",
    "\n",
    "# Gráficos de líneas para el promedio de sueldos por mes a lo largo de los años\n",
    "plt.figure(figsize=(14, 7))\n",
    "ax = sueldo_promedio_por_mes.T.plot(kind='line', title='Promedio de Sueldos por Mes')\n",
    "ax.set_xlabel('Mes')\n",
    "ax.set_ylabel('Sueldo Promedio')\n",
    "ax.xaxis.set_major_locator(ticker.MaxNLocator(integer=True))\n",
    "ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x)))\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/002-promedio_sueldos_por_mes.png')\n",
    "plt.close()\n",
    "\n",
    "# Top 10 tipos con mayores sueldos totales acumulados\n",
    "top_10_tipos_sueldos = df.groupby('Tipo')['Sueldo Neto'].sum().nlargest(10)\n",
    "\n",
    "# Gráficos de barras para los 10 tipos con mayores sueldos totales acumulados\n",
    "plt.figure(figsize=(14, 7))\n",
    "top_10_tipos_sueldos.plot(kind='bar', title='Top 10 Tipos con Mayores Sueldos Totales Acumulados')\n",
    "plt.xlabel('Tipo')\n",
    "plt.ylabel('Sueldo Total Acumulado')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/003-top_10_tipos_sueldos.png')\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# Boxplot de sueldos por tipo\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.boxplot(x='Tipo', y='Sueldo Neto', data=df[df['Tipo'].isin(top_10_tipos_sueldos.index)], showfliers=False)\n",
    "plt.title('Distribución de Sueldos por Tipo (Top 10)')\n",
    "plt.xlabel('Tipo')\n",
    "plt.ylabel('Sueldo Neto')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/004-distribucion_sueldos_por_tipo_top_10.png')\n",
    "plt.close()\n",
    "\n",
    "# Gráficos de líneas para los 10 tipos con mayores sueldos totales acumulados\n",
    "for tipo in top_10_tipos_sueldos.index:\n",
    "    df_tipo = df[df['Tipo'] == tipo].groupby('Fecha')['Sueldo Neto'].sum()\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    ax = df_tipo.plot(kind='line', title=f'Suma de Sueldos por Fecha para {tipo}')\n",
    "    ax.set_xlabel('Fecha')\n",
    "    ax.set_ylabel('Sueldo Total')\n",
    "    ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x)))\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'img/005-sueldos_totales_por_fecha_{tipo}.png')\n",
    "    plt.close()\n",
    "\n",
    "# Heatmap de la matriz de correlación entre los 10 tipos con mayores sueldos totales acumulados\n",
    "top_10_tipos_sueldos = df.groupby('Tipo')['Sueldo Neto'].sum().nlargest(10)\n",
    "for year in df['Año'].unique():\n",
    "    df_year = df[df['Año'] == year]\n",
    "    pivot_table = df_year[df_year['Tipo'].isin(top_10_tipos_sueldos.index)].pivot_table(index='Fecha', columns='Tipo', values='Sueldo Neto', aggfunc='sum')\n",
    "    correlation_matrix = pivot_table.corr()\n",
    "\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    sns.heatmap(correlation_matrix, cmap='coolwarm', annot=False)\n",
    "    plt.title(f'Matriz de Correlación entre Tipos (Top 10) en {year}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'img/006-matriz_correlacion_tipos_top_10_{year}.png')\n",
    "    plt.close()\n",
    "\n",
    "# Gráficos de líneas para sueldos totales por fecha con mínimo, máximo y promedio\n",
    "sueldo_totales_por_fecha = df.groupby('Fecha')['Sueldo Neto'].agg(['sum', 'min', 'max', 'mean'])\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(sueldo_totales_por_fecha.index, sueldo_totales_por_fecha['sum'], label='Suma')\n",
    "plt.plot(sueldo_totales_por_fecha.index, sueldo_totales_por_fecha['min'], label='Mínimo')\n",
    "plt.plot(sueldo_totales_por_fecha.index, sueldo_totales_por_fecha['max'], label='Máximo')\n",
    "plt.plot(sueldo_totales_por_fecha.index, sueldo_totales_por_fecha['mean'], label='Promedio')\n",
    "plt.title('Sueldos Totales por Fecha')\n",
    "plt.xlabel('Fecha')\n",
    "plt.ylabel('Sueldo')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.gca().yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x)))\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/007-sueldo_totales_por_fecha.png')\n",
    "plt.close()\n",
    "\n",
    "# Gráfica de barras de los 5 tipos con mayores sueldos netos totales acumulados por año\n",
    "top_5_tipos_sueldos = df.groupby('Tipo')['Sueldo Neto'].sum().nlargest(5)\n",
    "df_top_5_anual = df[df['Tipo'].isin(top_5_tipos_sueldos.index)].groupby(['Año', 'Tipo'])['Sueldo Neto'].sum().unstack()\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "df_top_5_anual.plot(kind='bar', stacked=True)\n",
    "plt.title('Top 5 Tipos con Mayores Sueldos Netos Totales Acumulados por Año')\n",
    "plt.xlabel('Año')\n",
    "plt.ylabel('Sueldo Total Acumulado')\n",
    "plt.gca().yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x)))\n",
    "plt.legend(title='Tipo')\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/008-top_5_tipos_anual.png')\n",
    "plt.close()\n",
    "\n",
    "# Gráfica de pastel por año para los tipos con mayores sueldos netos totales\n",
    "for year in df['Año'].unique():\n",
    "    df_year = df[df['Año'] == year]\n",
    "    top_10_tipos_anual = df_year.groupby('Tipo')['Sueldo Neto'].sum().nlargest(10)\n",
    "\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    top_10_tipos_anual.plot(kind='pie', autopct='%1.1f%%', startangle=140)\n",
    "    plt.title(f'Tipos con Mayores Sueldos Netos Totales en {year}')\n",
    "    plt.ylabel('')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'img/009-tipos_mayores_sueldos_netos_{year}.png')\n",
    "    plt.close()\n",
    "\n",
    "print(\"Gráficos generados exitosamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4aa4d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419cb46f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8378f1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro, f_oneway, ttest_ind, kruskal\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf1f778",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c808e3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2436b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7205ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar la normalidad de las muestras por tipo\n",
    "normalidad = df.groupby('Tipo')['Sueldo Neto'].apply(lambda x: shapiro(x)[1] if len(x) >= 3 else np.nan)\n",
    "print(\"Resultados de normalidad (p-values):\\n\", normalidad)\n",
    "\n",
    "# Tipos con datos suficientes para ANOVA o Kruskal-Wallis\n",
    "tipos_validos = normalidad.dropna().index\n",
    "\n",
    "# Filtrar el DataFrame para los tipos válidos\n",
    "df_validos = df[df['Tipo'].isin(tipos_validos)]\n",
    "\n",
    "# Prueba ANOVA si todas las muestras son normales\n",
    "anova_resultados = f_oneway(*[df_validos[df_validos['Tipo'] == tipo]['Sueldo Neto'] for tipo in tipos_validos])\n",
    "print('Resultados de ANOVA:', anova_resultados)\n",
    "\n",
    "if anova_resultados.pvalue < 0.05:\n",
    "    print(\"Existen diferencias significativas entre los tipos. Proceder con pruebas adicionales.\")\n",
    "    ttest_resultados = {}\n",
    "    for i in range(len(tipos_validos)):\n",
    "        for j in range(i+1, len(tipos_validos)):\n",
    "            tipo1 = tipos_validos[i]\n",
    "            tipo2 = tipos_validos[j]\n",
    "            ttest_resultados[f'{tipo1} vs {tipo2}'] = ttest_ind(df_validos[df_validos['Tipo'] == tipo1]['Sueldo Neto'],\n",
    "                                                                df_validos[df_validos['Tipo'] == tipo2]['Sueldo Neto'])\n",
    "    print(ttest_resultados)\n",
    "else:\n",
    "    print(\"No existen diferencias significativas entre los tipos según ANOVA.\")\n",
    "\n",
    "# Prueba Kruskal-Wallis si alguna muestra no es normal\n",
    "kruskal_resultados = kruskal(*[df_validos[df_validos['Tipo'] == tipo]['Sueldo Neto'] for tipo in tipos_validos])\n",
    "print('Resultados de Kruskal-Wallis:', kruskal_resultados)\n",
    "\n",
    "if kruskal_resultados.pvalue < 0.05:\n",
    "    print(\"Existen diferencias significativas entre los tipos. Proceder con prueba de Tukey.\")\n",
    "    tukey_resultados = pairwise_tukeyhsd(df_validos['Sueldo Neto'], df_validos['Tipo'])\n",
    "    print(tukey_resultados)\n",
    "else:\n",
    "    print(\"No existen diferencias significativas entre los tipos según Kruskal-Wallis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5cfa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import shapiro, f_oneway, ttest_ind, kruskal, norm, lognorm, expon\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Supongamos que el DataFrame df ya está cargado\n",
    "# df = pd.read_csv('csv/typed_itam.csv')\n",
    "# df['Fecha'] = pd.to_datetime(df['Fecha'])\n",
    "\n",
    "# Crear columnas de año y mes\n",
    "df['Año'] = df['Fecha'].dt.year\n",
    "df['Mes'] = df['Fecha'].dt.month\n",
    "\n",
    "# Filtrar los tipos con suficientes datos\n",
    "tipos_validos = df['Tipo'].unique()\n",
    "\n",
    "# Función para ajustar distribuciones\n",
    "def fit_distributions(data):\n",
    "    dist_names = ['norm', 'lognorm', 'expon']\n",
    "    dist_results = {}\n",
    "    for dist_name in dist_names:\n",
    "        dist = getattr(__import__('scipy.stats', fromlist=[dist_name]), dist_name)\n",
    "        params = dist.fit(data)\n",
    "        dist_results[dist_name] = params\n",
    "    return dist_results\n",
    "\n",
    "# Pruebas ANOVA y Kruskal-Wallis por mes\n",
    "resultados_anova = {}\n",
    "resultados_kruskal = {}\n",
    "distribuciones = {}\n",
    "\n",
    "for year in df['Año'].unique():\n",
    "    for month in df['Mes'].unique():\n",
    "        df_month = df[(df['Año'] == year) & (df['Mes'] == month)]\n",
    "        \n",
    "        if df_month.empty:\n",
    "            continue\n",
    "        \n",
    "        normalidad = df_month.groupby('Tipo')['Sueldo Neto'].apply(lambda x: shapiro(x)[1] if len(x) >= 3 else np.nan)\n",
    "        tipos_validos_mes = normalidad.dropna().index\n",
    "        df_validos_mes = df_month[df_month['Tipo'].isin(tipos_validos_mes)]\n",
    "        \n",
    "        if df_validos_mes.empty:\n",
    "            continue\n",
    "        \n",
    "        # Prueba ANOVA si todas las muestras son normales\n",
    "        if all(normalidad.dropna() > 0.05):\n",
    "            anova_resultados = f_oneway(*[df_validos_mes[df_validos_mes['Tipo'] == tipo]['Sueldo Neto'] for tipo in tipos_validos_mes])\n",
    "            resultados_anova[(year, month)] = anova_resultados\n",
    "            if anova_resultados.pvalue < 0.05:\n",
    "                ttest_resultados = {}\n",
    "                for i in range(len(tipos_validos_mes)):\n",
    "                    for j in range(i+1, len(tipos_validos_mes)):\n",
    "                        tipo1 = tipos_validos_mes[i]\n",
    "                        tipo2 = tipos_validos_mes[j]\n",
    "                        ttest_resultados[f'{tipo1} vs {tipo2}'] = ttest_ind(df_validos_mes[df_validos_mes['Tipo'] == tipo1]['Sueldo Neto'],\n",
    "                                                                            df_validos_mes[df_validos_mes['Tipo'] == tipo2]['Sueldo Neto'])\n",
    "                print(f\"Resultados de t-test para {year}-{month}:\\n\", ttest_resultados)\n",
    "        else:\n",
    "            kruskal_resultados = kruskal(*[df_validos_mes[df_validos_mes['Tipo'] == tipo]['Sueldo Neto'] for tipo in tipos_validos_mes])\n",
    "            resultados_kruskal[(year, month)] = kruskal_resultados\n",
    "            if kruskal_resultados.pvalue < 0.05:\n",
    "                tukey_resultados = pairwise_tukeyhsd(df_validos_mes['Sueldo Neto'], df_validos_mes['Tipo'])\n",
    "                print(f\"Resultados de Tukey para {year}-{month}:\\n\", tukey_resultados)\n",
    "                \n",
    "                distribuciones[(year, month)] = {}\n",
    "                for tipo in tipos_validos_mes:\n",
    "                    data = df_validos_mes[df_validos_mes['Tipo'] == tipo]['Sueldo Neto']\n",
    "                    distribuciones[(year, month)][tipo] = fit_distributions(data)\n",
    "                print(f\"Distribuciones ajustadas para {year}-{month}:\\n\", distribuciones[(year, month)])\n",
    "\n",
    "print(\"Resultados de ANOVA:\\n\", resultados_anova)\n",
    "print(\"Resultados de Kruskal-Wallis:\\n\", resultados_kruskal)\n",
    "print(\"Distribuciones ajustadas:\\n\", distribuciones)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e94d96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96501657",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d29f4b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3058319a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e015f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691cb22c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605a6286",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.groupby('dependencia')['Sueldo Neto'].describe().sort_values(by='max', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1851d424",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('dependencia')['Sueldo Neto'].describe(include='all').sort_values(by='max', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d8b625",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e546376",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dae5cae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01940c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121ede6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d300f2d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbae3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Supongamos que el DataFrame df ya está cargado\n",
    "\n",
    "# Estadísticas descriptivas para el campo \"dependencia\"\n",
    "dependencia_stats = df['dependencia'].describe()\n",
    "print(\"Estadísticas descriptivas para 'dependencia':\")\n",
    "print(dependencia_stats)\n",
    "\n",
    "# Estadísticas descriptivas para el campo \"Sueldo Neto\" agrupadas por \"dependencia\"\n",
    "sueldo_stats = df.groupby('dependencia')['Sueldo Neto'].describe().sort_values(by='mean', ascending=False)\n",
    "\n",
    "sueldo_stats = df.groupby('dependencia')['Sueldo Neto'].describe().sort_values(by='mean', ascending=False)\n",
    "\n",
    "# Renombrar las columnas para mayor claridad\n",
    "sueldo_stats.rename(columns={\n",
    "    'count': 'Cantidad',\n",
    "    'mean': 'Promedio',\n",
    "    'std': 'Desviación Estándar',\n",
    "    'min': 'Mínimo',\n",
    "    '25%': 'Primer Cuartil',\n",
    "    '50%': 'Mediana',\n",
    "    '75%': 'Tercer Cuartil',\n",
    "    'max': 'Máximo'\n",
    "}, inplace=True)\n",
    "\n",
    "print(\"\\nEstadísticas descriptivas para 'Sueldo Neto' agrupadas por 'dependencia':\")\n",
    "print(sueldo_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a6b8aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1f943a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc220aad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19aa598b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Supongamos que el DataFrame df ya está cargado\n",
    "\n",
    "# Estadísticas descriptivas para el campo \"dependencia\"\n",
    "dependencia_stats = df['dependencia'].describe()\n",
    "print(\"Estadísticas descriptivas para 'dependencia':\")\n",
    "print(dependencia_stats)\n",
    "\n",
    "# Estadísticas descriptivas para el campo \"Sueldo Neto\" agrupadas por \"dependencia\"\n",
    "sueldo_stats = df.groupby('dependencia')['Sueldo Neto'].describe().sort_values(by='mean', ascending=False)\n",
    "\n",
    "# Renombrar las columnas para mayor claridad\n",
    "sueldo_stats.rename(columns={\n",
    "    'count': 'Cantidad',\n",
    "    'mean': 'Promedio',\n",
    "    'std': 'Desviación Estándar',\n",
    "    'min': 'Mínimo',\n",
    "    '25%': 'Primer Cuartil',\n",
    "    '50%': 'Mediana',\n",
    "    '75%': 'Tercer Cuartil',\n",
    "    'max': 'Máximo'\n",
    "}, inplace=True)\n",
    "\n",
    "# print(\"\\nEstadísticas descriptivas para 'Sueldo Neto' agrupadas por 'dependencia':\")\n",
    "print(sueldo_stats)\n",
    "\n",
    "# Guardar los resultados en archivos CSV\n",
    "dependencia_stats.to_csv('resultados/estadisticas_dependencia.csv')\n",
    "sueldo_stats.to_csv('resultados/estadisticas_sueldo_neto_por_dependencia.csv')\n",
    "\n",
    "# Ordenar las estadísticas descriptivas por la dependencia con mayor cantidad de empleados de mayor a menor\n",
    "sueldo_stats = sueldo_stats.sort_values(by='Cantidad', ascending=False)\n",
    "\n",
    "# print(\"\\nEstadísticas descriptivas para 'Sueldo Neto' agrupadas por 'dependencia' (ordenadas por cantidad de empleados):\")\n",
    "# print(sueldo_stats)\n",
    "\n",
    "# Guardar los resultados en archivos CSV\n",
    "sueldo_stats.to_csv('resultados/estadisticas_empleados_por_dependencia.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d1f399",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572a6172",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45fe0a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a92eab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47fd4fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90b520a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9e9bb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6b93f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "from typing import Tuple, List\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import shapiro, f_oneway, ttest_ind, kruskal\n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "\n",
    "\n",
    "def print_tabulate(df: pd.DataFrame):\n",
    "    print(tabulate(df, headers=df.columns, tablefmt='orgtbl'))\n",
    "\n",
    "\n",
    "def categorize(name:str)->str:\n",
    "    if 'PREPARATORIA' in name or 'PREPA.' in name:\n",
    "        return 'PREPARATORIA'\n",
    "    if 'FACULTAD' in name or 'FAC.' in name:\n",
    "        return 'FACULTAD'\n",
    "    if 'HOSPITAL' in name:\n",
    "        return 'HOSPITAL'\n",
    "    if 'CENTRO' in name or 'CTRO.' in name or 'C.' in name or 'INVESTIGAC' in name :\n",
    "        return 'CENTRO'\n",
    "    if 'SECRETARÍA' in name or 'SECRETARIA' in name or 'SRIA.' in name or 'DIRECCIÓN' in name or 'DIRECCION' in name or \\\n",
    "       'DEPARTAMENTO' in name or 'DEPTO.' in name or 'CONTRALORIA' in name or 'AUDITORIA' in name or 'TESORERIA' in name \\\n",
    "       or 'ESCOLAR' in name or 'ABOGACÍA' in name  or 'JUNTA' in name  or 'RECTORIA' in name  or 'IMAGEN' in name :\n",
    "        return 'ADMIN'\n",
    "    return 'OTRO'\n",
    "\n",
    "def transform_into_typed_df(raw_df: pd.DataFrame)->pd.DataFrame:\n",
    "    raw_df[\"Fecha\"] = pd.to_datetime(raw_df[\"anio\"].map(str)+ \"-\" + raw_df[\"mes\"].map(str), format=\"%Y-%m\")\n",
    "    raw_df = raw_df.drop(['anio', 'mes'], axis=1)\n",
    "    raw_df[\"Tipo\"] = raw_df[\"dependencia\"].map(categorize)\n",
    "    return raw_df\n",
    "\n",
    "\n",
    "\n",
    "def normalize_data(file_name:str) -> str:\n",
    "    df_complete = pd.read_csv(file_name)\n",
    "    df_complete[\"Fecha\"] = pd.to_datetime(df_complete[\"anio\"].map(str)+ \"-\" + df_complete[\"mes\"].map(str), format=\"%Y-%m\")\n",
    "    df_complete = df_complete.drop(['anio', 'mes'], axis=1)\n",
    "    df_complete[\"Tipo\"] = df_complete[\"dependencia\"].map(categorize)\n",
    "    df_complete.to_csv(\"csv/typed_uanl.csv\", index=False)\n",
    "    return \"csv/typed_uanl.csv\"\n",
    "\n",
    "def analysis_dependencia(file_name:str)->None:\n",
    "    df_complete = pd.read_csv(file_name)\n",
    "    df_complete[\"Fecha\"] = pd.to_datetime(df_complete[\"Fecha\"], format=\"%Y-%m-%d\")\n",
    "    df_complete[\"anio\"] = df_complete[\"Fecha\"].dt.year\n",
    "    # df_by_dep = df_complete.groupby([\"dependencia\", \"anio\"]).agg({'Sueldo Neto': ['sum', 'count']})\n",
    "    # print_tabulate(df_by_dep.head())\n",
    "    df_by_dep = df_complete.groupby([\"dependencia\", \"Fecha\"]).agg({'Sueldo Neto': ['sum', 'count', 'mean', 'min', 'max']})\n",
    "    df_by_dep = df_by_dep.reset_index()\n",
    "    print_tabulate(df_by_dep.head())\n",
    "    df_by_dep.to_csv(\"csv/uanl_dependencia_mes.csv\")\n",
    "\n",
    "\n",
    "def create_boxplot_by_type(file_name:str, column: str, agg_fn= pd.DataFrame.sum):\n",
    "    df_complete = pd.read_csv(file_name)\n",
    "    df_by_type = df_complete.groupby([column,\"Fecha\"])[[\"Sueldo Neto\"]].aggregate(agg_fn)# .count()\n",
    "    df_by_type.boxplot(by = column, figsize=(27,18))\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.savefig(f\"img2/boxplot_{column}.png\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_by_dep(df: pd.DataFrame, dep:str)->None:\n",
    "    df[df[\"dependencia\"] == dep].plot(y =[\"Sueldo Neto\"])\n",
    "    plt.savefig(f\"img2/lt_{dep}.png\")\n",
    "    df[df[\"dependencia\"] == dep].boxplot(by ='dependencia')\n",
    "    plt.savefig(f\"img2/bplt_{dep}.png\")\n",
    "\n",
    "\n",
    "def create_plot_por_dependencia(file_name:str):\n",
    "    df_complete = pd.read_csv(file_name)\n",
    "    df_by_dep = df_complete.groupby([\"dependencia\", \"Fecha\"])[[\"Sueldo Neto\"]].aggregate(pd.DataFrame.mean)\n",
    "    df_by_dep.reset_index(inplace=True)\n",
    "    df_by_dep.set_index(\"Fecha\", inplace=True)\n",
    "\n",
    "    for dep in set(df_by_dep[\"dependencia\"]):\n",
    "       plot_by_dep(df_by_dep, dep)\n",
    "    df_aux = df_complete.groupby([\"Fecha\",\"dependencia\"])[['Sueldo Neto']].mean().unstack()\n",
    "    df_aux.plot(y = 'Sueldo Neto', legend=False, figsize=(32,18))\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.savefig(\"img2/foo.png\")\n",
    "    plt.close()\n",
    "\n",
    "def anova(df_aux: pd.DataFrame, str_ols: str):\n",
    "    # shaphiro-wills\n",
    "    # Levenes or barletts\n",
    "    modl = ols(str_ols, data=df_aux).fit()\n",
    "    anova_df = sm.stats.anova_lm(modl, typ=2)\n",
    "    if anova_df[\"PR(>F)\"][0] < 0.005:\n",
    "        print(\"hay diferencias\")\n",
    "        print(anova_df)\n",
    "        # Prueba tukey\n",
    "        # imprimir los resultados\n",
    "    else:\n",
    "        print(\"No hay diferencias\")\n",
    "\n",
    "def anova_1(file_name: str):\n",
    "    df_complete = pd.read_csv(file_name)\n",
    "    df_by_type = df_complete.groupby([\"Tipo\", \"Fecha\"])[[\"Sueldo Neto\"]].aggregate(pd.DataFrame.sum)\n",
    "    df_by_type.reset_index(inplace=True)\n",
    "    df_by_type.set_index(\"Fecha\", inplace=True)\n",
    "    df_by_type.reset_index(inplace=True)\n",
    "    df_aux = df_by_type.rename(columns={\"Sueldo Neto\": \"GastoSalarios\"}).drop(['Fecha'], axis=1)\n",
    "    print(df_aux.head())\n",
    "    anova(df_aux, \"GastoSalarios ~ Tipo\")\n",
    "\n",
    "def analysis(file_name: str) -> None:\n",
    "    df_complete = pd.read_csv(file_name)\n",
    "    # print_tabulate(df_complete[[\"dependencia\",\"Tipo\"]].drop_duplicates().head(150))\n",
    "    df_by_dep = df_complete.groupby([\"dependencia\", \"Fecha\"])[[\"Sueldo Neto\"]].aggregate(pd.DataFrame.sum)\n",
    "\n",
    "    # df_by_dep_by_anio = df_by_dep.groupby([\"dependencia\",\"anio\"]).aggregate(pd.DataFrame.sum).sort_values(by=[\"dependencia\", \"anio\"], ascending=True)\n",
    "    df_by_dep.reset_index(inplace=True)\n",
    "    df_by_dep.set_index(\"Fecha\", inplace=True)\n",
    "    # print_tabulate(df_by_dep.head(5))\n",
    "\n",
    "    for dep in set(df_by_dep[\"dependencia\"]):\n",
    "        plot_by_dep(df_by_dep, dep)\n",
    "    \n",
    "    df_by_type = df_complete.groupby([\"Tipo\", \"Fecha\"])[[\"Sueldo Neto\"]].aggregate(pd.DataFrame.sum)\n",
    "    df_by_type.boxplot(by='Tipo', figsize=(18,9))\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.savefig(\"img2/boxplot_tipo.png\")\n",
    "    plt.close()\n",
    "\n",
    "    aux = df_complete.groupby([\"Tipo\"])[[\"Sueldo Neto\"]].aggregate(pd.DataFrame.sum)\n",
    "    aux.reset_index(inplace=True)\n",
    "    df_by_type.reset_index(inplace=True)\n",
    "    df_aux = df_by_type.rename(columns={\"Sueldo Neto\": \"GastoSalarios\"}).drop(['Fecha'], axis=1)\n",
    "    print(df_aux.head())\n",
    "\n",
    "    # Prueba ANOVA\n",
    "    modl = ols(\"GastoSalarios ~ Tipo\", data=df_aux).fit()\n",
    "    anova_df = sm.stats.anova_lm(modl, typ=2)\n",
    "    if anova_df[\"PR(>F)\"][0] < 0.005:\n",
    "        print(\"Hay diferencias\")\n",
    "        print(anova_df)\n",
    "        # Prueba Tukey\n",
    "        tukey_resultados = pairwise_tukeyhsd(df_aux['GastoSalarios'], df_aux['Tipo'])\n",
    "        print(tukey_resultados)\n",
    "    else:\n",
    "        print(\"No hay diferencias\")\n",
    "\n",
    "\n",
    "\n",
    "def create_typed_df(filename:str)-> pd.DataFrame:\n",
    "    df_complete = pd.read_csv(filename)\n",
    "    raw_df = transform_into_typed_df(df_complete)\n",
    "    print_tabulate(raw_df.head(50))\n",
    "    raw_df.to_csv(\"csv/typed_uanl.csv\", index=False)\n",
    "    return raw_df\n",
    "\n",
    "def show_type_of_department():\n",
    "    df_complete = pd.read_csv(\"csv/typed_uanl.csv\")\n",
    "    print_tabulate(df_complete[[\"dependencia\",\"Tipo\"]].\\\n",
    "                   drop_duplicates().head(150))\n",
    "\n",
    "def show_data_by_dependency_and_date():\n",
    "    df_complete = pd.read_csv(\"csv/typed_uanl.csv\")\n",
    "    df_by_dep = df_complete.groupby([\"dependencia\", \"Fecha\"])[[\"Sueldo Neto\"]].aggregate(pd.DataFrame.sum)\n",
    "    df_by_dep.reset_index(inplace=True)\n",
    "    df_by_dep.set_index(\"Fecha\", inplace=True)\n",
    "    print_tabulate(df_by_dep[df_by_dep[\"dependencia\"]== \"FAC. DE CIENCIAS FISICO-MATEMATICAS\"].head(50))\n",
    "\n",
    "\n",
    "def show_data_by_type_and_date():\n",
    "    df_complete = pd.read_csv(\"csv/typed_uanl.csv\")\n",
    "    df_by_type = df_complete.groupby([\"Tipo\", \"Fecha\"])[[\"Sueldo Neto\"]].aggregate(pd.DataFrame.sum)\n",
    "    df_by_type.reset_index(inplace=True)\n",
    "    df_by_type.set_index(\"Fecha\", inplace=True)\n",
    "    print_tabulate(df_by_type.head(150))\n",
    "\n",
    "\n",
    "def show_salary_and_count_by_type_and_date():\n",
    "    df_complete = pd.read_csv(\"csv/typed_uanl.csv\")\n",
    "    df_by_type = df_complete.groupby([\"Tipo\", \"Fecha\"]).agg({'Sueldo Neto': ['sum', 'count', 'mean', 'min']})\n",
    "    df_by_type.reset_index(inplace=True)\n",
    "    df_by_type.columns = ['Tipo', 'Fecha', 'Total_sueldos', 'Conteo_Empleado', 'Promedio_sueldo', 'Salario_Maximo']\n",
    "    df_by_type.set_index(\"Fecha\", inplace=True)\n",
    "    print_tabulate(df_by_type.head(150))\n",
    "\n",
    "def show_salary_and_count_by_dependency_and_date():\n",
    "    df_complete = pd.read_csv(\"csv/typed_uanl.csv\")\n",
    "    df_by_type = df_complete.groupby([\"dependencia\", \"Fecha\"]).agg({'Sueldo Neto': ['sum', 'count', 'mean', 'max']})\n",
    "    df_by_type.reset_index(inplace=True)\n",
    "    df_by_type.columns = ['Tipo', 'Fecha', 'Total_sueldos', 'Conteo_Empleado', 'Promedio_sueldo', 'Salario_Maximo']\n",
    "    df_by_type.set_index(\"Fecha\", inplace=True)\n",
    "    print_tabulate(df_by_type)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # analysis_dependencia(\"csv/typed_uanl.csv\")\n",
    "    # create_typed_df(\"csv/uanl.csv\")\n",
    "    # show_data_by_dependency_and_date()\n",
    "    # show_data_by_type_and_date()\n",
    "    # show_salary_and_count_by_type_and_date()\n",
    "    # show_salary_and_count_by_dependency_and_date()\n",
    "    \n",
    "    #### analysis(\"csv/typed_uanl.csv\")\n",
    "    \n",
    "    # create_boxplot_by_type(\"csv/typed_uanl.csv\", 'dependencia', pd.DataFrame.mean)#\"Tipo\")\n",
    "    create_plot_por_dependencia(\"csv/typed_uanl.csv\")\n",
    "    # anova_1(\"csv/typed_uanl.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76f1421",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e3b8ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f04b0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0560688",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
