{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "758d91fe",
   "metadata": {},
   "source": [
    "Práctica 1 Análisis exploratorio\n",
    "Utilizando el dataset de los pagos de la UANL (https://github.com/ppGodel/data_mining/blob/main/csv/typed_uanl.csv) van a realizar un análisis exploratorio. Hay que crear una script donde realices lo siguiente:\n",
    " \n",
    "1.\tIdentificar las entidades (que es lo que puede ser sujeto de estudio) del conjunto. agrégalo como un comentario en tu script.\n",
    "2.\tObtener las estadísticas (descriptiva) de cada entidad (min, max, avg, std)\n",
    "3.\tHacer agrupaciones por las entidades y sacar estadísticas de las agrupaciones.\n",
    "4.\tCrear imágenes de estas estadísticas, ya sean histogramas, graficas de pastel, etc., al menos 3 graficas diferentes, Hay que crear muchas imágenes, así que creen ciclos y recorran las agrupaciones. \n",
    "5.\tDe alguna de las agrupaciones, hacer una prueba ANOVA, para ver si hay diferencias entre los elementos. recordando, hay que probar que las muestras son o no normales. sí son normales anova para la prueba y t-student para saber quién es el diferente. Si la muestra no es normal, prueba con kruskall-wallis y tukey para saber quién es el diferente.  \n",
    "Realiza un reporte escrito de tus hallazgos. No quiero una descripción de que hiciste, sino de que encontraste, cosas que no sabias y supiste una vez que comenzaste a analizar los datos, cuenta que cosas guiaron tu atención para encontrar información que consideras significativa, y muestra esos hallazgos con imágenes, así que prepara tus imágenes para que alguien las vea.\n",
    "Hay que crear un repositorio de github/gitlab con 2 carpetas en la raíz del repositorio: Reportes y Practicas. En Reporte estará el reporte en formato PDF con el nombre Practica#.pdf donde # es el numero de la practica al que corresponde. En  la carpeta de prácticas por cada practica habrá una carpeta de nombre Practica# donde estará todo el código, imágenes, conjuntos de datos que usaste para la práctica.\n",
    " \n",
    "Link para pasarme tu repositorio:\n",
    "https://forms.office.com/r/YuvnZHMif0\n",
    "La fecha límite para subir el reporte y el código a git es el domingo 30 de junio. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3583dfc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9e5bf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff31fc08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26435970",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfa0b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869c8b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25439911",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb1e478",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7a809e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41dc747",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49f9183",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install statsmodels.regression.linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86264df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import shapiro, f_oneway, ttest_ind, kruskal\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5aa7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Identificar las entidades\n",
    "# Entidades: Nombre (empleado), Sueldo Neto, Dependencia, Fecha, Tipo\n",
    "\n",
    "# Cargar los datos desde el archivo CSV\n",
    "df = pd.read_csv('csv/typed_uanl.csv')\n",
    "\n",
    "# Convertir la columna 'Fecha' a tipo datetime\n",
    "df['Fecha'] = pd.to_datetime(df['Fecha'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0eb859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Obtener las estadísticas descriptivas de cada entidad\n",
    "estadisticas_descriptivas = df.describe(include='all')\n",
    "print(estadisticas_descriptivas)\n",
    "\n",
    "# Guardar las estadísticas descriptivas en un archivo CSV\n",
    "estadisticas_descriptivas.to_csv('estadisticas_descriptivas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44077e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "estadisticas_descriptivas = df[\"dependencia\"].describe(include='all')\n",
    "print(estadisticas_descriptivas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c793999e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Supongamos que el DataFrame df ya está cargado\n",
    "\n",
    "# Estadísticas descriptivas para el campo \"dependencia\"\n",
    "dependencia_stats = df['dependencia'].describe()\n",
    "print(\"Estadísticas descriptivas para 'dependencia':\")\n",
    "print(dependencia_stats)\n",
    "\n",
    "# Estadísticas descriptivas para el campo \"Sueldo Neto\" agrupadas por \"dependencia\"\n",
    "sueldo_stats = df.groupby('dependencia')['Sueldo Neto'].describe().sort_values(by='mean', ascending=False)\n",
    "\n",
    "# Renombrar las columnas para mayor claridad\n",
    "sueldo_stats.rename(columns={\n",
    "    'count': 'Cantidad',\n",
    "    'mean': 'Promedio',\n",
    "    'std': 'Desviación Estándar',\n",
    "    'min': 'Mínimo',\n",
    "    '25%': 'Primer Cuartil',\n",
    "    '50%': 'Mediana',\n",
    "    '75%': 'Tercer Cuartil',\n",
    "    'max': 'Máximo'\n",
    "}, inplace=True)\n",
    "\n",
    "# print(\"\\nEstadísticas descriptivas para 'Sueldo Neto' agrupadas por 'dependencia':\")\n",
    "print(sueldo_stats)\n",
    "\n",
    "# Guardar los resultados en archivos CSV\n",
    "dependencia_stats.to_csv('estadisticas_dependencia.csv')\n",
    "sueldo_stats.to_csv('estadisticas_sueldo_neto_por_dependencia.csv')\n",
    "\n",
    "# Ordenar las estadísticas descriptivas por la dependencia con mayor cantidad de empleados de mayor a menor\n",
    "sueldo_stats = sueldo_stats.sort_values(by='Cantidad', ascending=False)\n",
    "\n",
    "# print(\"\\nEstadísticas descriptivas para 'Sueldo Neto' agrupadas por 'dependencia' (ordenadas por cantidad de empleados):\")\n",
    "# print(sueldo_stats)\n",
    "\n",
    "# Guardar los resultados en archivos CSV\n",
    "sueldo_stats.to_csv('estadisticas_empleados_por_dependencia.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fa1db9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Supongamos que el DataFrame df ya está cargado\n",
    "# df = pd.read_csv('csv/typed_itam.csv')\n",
    "# df['Fecha'] = pd.to_datetime(df['Fecha'])\n",
    "\n",
    "# Estadísticas descriptivas para el campo \"dependencia\"\n",
    "dependencia_stats = df['dependencia'].describe()\n",
    "print(\"Estadísticas descriptivas para 'dependencia':\")\n",
    "print(dependencia_stats)\n",
    "\n",
    "# Estadísticas descriptivas para el campo \"Sueldo Neto\" agrupadas por \"dependencia\"\n",
    "sueldo_stats = df.groupby('dependencia')['Sueldo Neto'].describe()\n",
    "\n",
    "# Renombrar las columnas para mayor claridad\n",
    "sueldo_stats.rename(columns={\n",
    "    'count': 'Cantidad',\n",
    "    'mean': 'Promedio',\n",
    "    'std': 'Desviación Estándar',\n",
    "    'min': 'Mínimo',\n",
    "    '25%': 'Primer Cuartil',\n",
    "    '50%': 'Mediana',\n",
    "    '75%': 'Tercer Cuartil',\n",
    "    'max': 'Máximo'\n",
    "}, inplace=True)\n",
    "\n",
    "# Ordenar las estadísticas descriptivas por la dependencia con mayor cantidad de empleados de mayor a menor\n",
    "sueldo_stats = sueldo_stats.sort_values(by='Cantidad', ascending=False)\n",
    "\n",
    "print(\"\\nEstadísticas descriptivas para 'Sueldo Neto' agrupadas por 'dependencia' (ordenadas por cantidad de empleados):\")\n",
    "print(sueldo_stats)\n",
    "\n",
    "# Estadísticas descriptivas para el campo \"Sueldo Neto\" agrupadas por \"Fecha\"\n",
    "fecha_stats = df.groupby('Fecha')['Sueldo Neto'].describe()\n",
    "\n",
    "# Renombrar las columnas para mayor claridad\n",
    "fecha_stats.rename(columns={\n",
    "    'count': 'Cantidad',\n",
    "    'mean': 'Promedio',\n",
    "    'std': 'Desviación Estándar',\n",
    "    'min': 'Mínimo',\n",
    "    '25%': 'Primer Cuartil',\n",
    "    '50%': 'Mediana',\n",
    "    '75%': 'Tercer Cuartil',\n",
    "    'max': 'Máximo'\n",
    "}, inplace=True)\n",
    "\n",
    "# Ordenar las estadísticas descriptivas por fecha\n",
    "fecha_stats = fecha_stats.sort_index()\n",
    "\n",
    "print(\"\\nEstadísticas descriptivas para 'Sueldo Neto' agrupadas por 'Fecha':\")\n",
    "print(fecha_stats)\n",
    "\n",
    "# Guardar los resultados en archivos CSV\n",
    "dependencia_stats.to_csv('estadisticas_dependencia.csv')\n",
    "sueldo_stats.to_csv('estadisticas_sueldo_neto_por_dependencia.csv')\n",
    "fecha_stats.to_csv('estadisticas_sueldo_neto_por_fecha.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5f983c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b316ade4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb912a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Hacer agrupaciones por las entidades y sacar estadísticas de las agrupaciones\n",
    "agrupacion_dependencia = df.groupby('dependencia')['Sueldo Neto'].describe()\n",
    "print(agrupacion_dependencia)\n",
    "\n",
    "# Guardar las estadísticas de agrupaciones en un archivo CSV\n",
    "agrupacion_dependencia.to_csv('estadisticas_agrupacion_dependencia.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c45ce5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd30f948",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffe5767",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9706caf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory Data Analysis (EDA), Análisis Exploratorio de Datos, para evitar correlaciones entre sus regresores\n",
    "correlation=dataset.corr()\n",
    "pyplot.figure(figsize=(15,15))\n",
    "pyplot.title(\"Correlation Matrix\")\n",
    "sns.heatmap(correlation, vmax=1, square=True, annot=True, fmt='.2f', cmap='cubehelix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015b0b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.figure(figsize=(15,15))\n",
    "scatter_matrix(dataset,figsize=(12,12))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7b8e15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5bed3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95902188",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42428275",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265e9f3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca1d07b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07997a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Crear imágenes de estas estadísticas\n",
    "\n",
    "# Histograma de Sueldo Neto\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['Sueldo Neto'], kde=True, bins=30)\n",
    "plt.title('Histograma de Sueldo Neto')\n",
    "plt.xlabel('Sueldo Neto')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.savefig('histograma_sueldo_neto.png')\n",
    "\n",
    "# Gráfica de pastel de Dependencias\n",
    "plt.figure(figsize=(10, 6))\n",
    "df['dependencia'].value_counts().plot.pie(autopct='%1.1f%%')\n",
    "plt.title('Distribución de Dependencias')\n",
    "plt.ylabel('')\n",
    "plt.savefig('pastel_dependencias.png')\n",
    "\n",
    "# Boxplot de Sueldo Neto por Dependencia\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.boxplot(x='dependencia', y='Sueldo Neto', data=df)\n",
    "plt.title('Boxplot de Sueldo Neto por Dependencia')\n",
    "plt.xticks(rotation=90)\n",
    "plt.savefig('boxplot_sueldo_dependencia.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea751183",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea17c8cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5cb11b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d611aca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Supongamos que el DataFrame df ya está cargado\n",
    "# df = pd.read_csv('csv/typed_itam.csv')\n",
    "# df['Fecha'] = pd.to_datetime(df['Fecha'])\n",
    "\n",
    "# Estadísticas descriptivas para el campo \"dependencia\"\n",
    "dependencia_stats = df['dependencia'].describe()\n",
    "print(\"Estadísticas descriptivas para 'dependencia':\")\n",
    "print(dependencia_stats)\n",
    "\n",
    "# Estadísticas descriptivas para el campo \"Sueldo Neto\" agrupadas por \"dependencia\"\n",
    "sueldo_stats = df.groupby('dependencia')['Sueldo Neto'].describe()\n",
    "\n",
    "# Renombrar las columnas para mayor claridad\n",
    "sueldo_stats.rename(columns={\n",
    "    'count': 'Cantidad',\n",
    "    'mean': 'Promedio',\n",
    "    'std': 'Desviación Estándar',\n",
    "    'min': 'Mínimo',\n",
    "    '25%': 'Primer Cuartil',\n",
    "    '50%': 'Mediana',\n",
    "    '75%': 'Tercer Cuartil',\n",
    "    'max': 'Máximo'\n",
    "}, inplace=True)\n",
    "\n",
    "# Ordenar las estadísticas descriptivas por la dependencia con mayor cantidad de empleados de mayor a menor\n",
    "sueldo_stats = sueldo_stats.sort_values(by='Cantidad', ascending=False)\n",
    "\n",
    "print(\"\\nEstadísticas descriptivas para 'Sueldo Neto' agrupadas por 'dependencia' (ordenadas por cantidad de empleados):\")\n",
    "print(sueldo_stats)\n",
    "\n",
    "# Estadísticas descriptivas para el campo \"Sueldo Neto\" agrupadas por \"Fecha\"\n",
    "fecha_stats = df.groupby('Fecha')['Sueldo Neto'].describe()\n",
    "\n",
    "# Renombrar las columnas para mayor claridad\n",
    "fecha_stats.rename(columns={\n",
    "    'count': 'Cantidad',\n",
    "    'mean': 'Promedio',\n",
    "    'std': 'Desviación Estándar',\n",
    "    'min': 'Mínimo',\n",
    "    '25%': 'Primer Cuartil',\n",
    "    '50%': 'Mediana',\n",
    "    '75%': 'Tercer Cuartil',\n",
    "    'max': 'Máximo'\n",
    "}, inplace=True)\n",
    "\n",
    "# Ordenar las estadísticas descriptivas por fecha\n",
    "fecha_stats = fecha_stats.sort_index()\n",
    "\n",
    "print(\"\\nEstadísticas descriptivas para 'Sueldo Neto' agrupadas por 'Fecha':\")\n",
    "print(fecha_stats)\n",
    "\n",
    "# Guardar los resultados en archivos CSV\n",
    "dependencia_stats.to_csv('estadisticas_dependencia.csv')\n",
    "sueldo_stats.to_csv('estadisticas_sueldo_neto_por_dependencia.csv')\n",
    "fecha_stats.to_csv('estadisticas_sueldo_neto_por_fecha.csv')\n",
    "\n",
    "# Crear gráficas separadas por año para las dependencias y los sueldos totales por mes\n",
    "df['Año'] = df['Fecha'].dt.year\n",
    "df['Mes'] = df['Fecha'].dt.month\n",
    "\n",
    "sueldo_por_mes = df.groupby(['Año', 'Mes'])['Sueldo Neto'].sum().unstack()\n",
    "\n",
    "for year in sueldo_por_mes.index:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sueldo_por_mes.loc[year].plot(kind='bar')\n",
    "    plt.title(f'Sueldos Totales por Mes en {year}')\n",
    "    plt.xlabel('Mes')\n",
    "    plt.ylabel('Sueldo Total')\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'img/sueldos_totales_por_mes_{year}.png')\n",
    "    plt.close()\n",
    "\n",
    "# Crear gráficas por dependencia con la suma de sueldos por fecha\n",
    "sueldo_por_fecha_dependencia = df.groupby(['dependencia', 'Fecha'])['Sueldo Neto'].sum().unstack()\n",
    "\n",
    "for dep in sueldo_por_fecha_dependencia.index:\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    sueldo_por_fecha_dependencia.loc[dep].plot(kind='line')\n",
    "    plt.title(f'Suma de Sueldos por Fecha para {dep}')\n",
    "    plt.xlabel('Fecha')\n",
    "    plt.ylabel('Sueldo Total')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'img/sueldos_totales_por_fecha_{dep}.png')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8811fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Supongamos que el DataFrame df ya está cargado\n",
    "# df = pd.read_csv('csv/typed_itam.csv')\n",
    "# df['Fecha'] = pd.to_datetime(df['Fecha'])\n",
    "\n",
    "# Estadísticas descriptivas para el campo \"dependencia\"\n",
    "dependencia_stats = df['dependencia'].describe()\n",
    "print(\"Estadísticas descriptivas para 'dependencia':\")\n",
    "print(dependencia_stats)\n",
    "\n",
    "# Estadísticas descriptivas para el campo \"Sueldo Neto\" agrupadas por \"dependencia\"\n",
    "sueldo_stats = df.groupby('dependencia')['Sueldo Neto'].describe()\n",
    "\n",
    "# Renombrar las columnas para mayor claridad\n",
    "sueldo_stats.rename(columns={\n",
    "    'count': 'Cantidad',\n",
    "    'mean': 'Promedio',\n",
    "    'std': 'Desviación Estándar',\n",
    "    'min': 'Mínimo',\n",
    "    '25%': 'Primer Cuartil',\n",
    "    '50%': 'Mediana',\n",
    "    '75%': 'Tercer Cuartil',\n",
    "    'max': 'Máximo'\n",
    "}, inplace=True)\n",
    "\n",
    "# Ordenar las estadísticas descriptivas por la dependencia con mayor cantidad de empleados de mayor a menor\n",
    "sueldo_stats = sueldo_stats.sort_values(by='Cantidad', ascending=False)\n",
    "\n",
    "print(\"\\nEstadísticas descriptivas para 'Sueldo Neto' agrupadas por 'dependencia' (ordenadas por cantidad de empleados):\")\n",
    "print(sueldo_stats)\n",
    "\n",
    "# Estadísticas descriptivas para el campo \"Sueldo Neto\" agrupadas por \"Fecha\"\n",
    "fecha_stats = df.groupby('Fecha')['Sueldo Neto'].describe()\n",
    "\n",
    "# Renombrar las columnas para mayor claridad\n",
    "fecha_stats.rename(columns={\n",
    "    'count': 'Cantidad',\n",
    "    'mean': 'Promedio',\n",
    "    'std': 'Desviación Estándar',\n",
    "    'min': 'Mínimo',\n",
    "    '25%': 'Primer Cuartil',\n",
    "    '50%': 'Mediana',\n",
    "    '75%': 'Tercer Cuartil',\n",
    "    'max': 'Máximo'\n",
    "}, inplace=True)\n",
    "\n",
    "# Ordenar las estadísticas descriptivas por fecha\n",
    "fecha_stats = fecha_stats.sort_index()\n",
    "\n",
    "print(\"\\nEstadísticas descriptivas para 'Sueldo Neto' agrupadas por 'Fecha':\")\n",
    "print(fecha_stats)\n",
    "\n",
    "# Guardar los resultados en archivos CSV\n",
    "dependencia_stats.to_csv('estadisticas_dependencia.csv')\n",
    "sueldo_stats.to_csv('estadisticas_sueldo_neto_por_dependencia.csv')\n",
    "fecha_stats.to_csv('estadisticas_sueldo_neto_por_fecha.csv')\n",
    "\n",
    "# Crear gráficas separadas por año para las dependencias y los sueldos totales por mes\n",
    "df['Año'] = df['Fecha'].dt.year\n",
    "df['Mes'] = df['Fecha'].dt.month\n",
    "\n",
    "sueldo_por_mes = df.groupby(['Año', 'Mes'])['Sueldo Neto'].sum().unstack()\n",
    "\n",
    "for year in sueldo_por_mes.index:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sueldo_por_mes.loc[year].plot(kind='bar')\n",
    "    plt.title(f'Sueldos Totales por Mes en {year}')\n",
    "    plt.xlabel('Mes')\n",
    "    plt.ylabel('Sueldo Total')\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'img/sueldos_totales_por_mes_{year}.png')\n",
    "    plt.close()\n",
    "\n",
    "# Crear gráficas por dependencia con la suma de sueldos por fecha\n",
    "sueldo_por_fecha_dependencia = df.groupby(['dependencia', 'Fecha'])['Sueldo Neto'].sum().unstack().transpose()\n",
    "\n",
    "for dep in sueldo_por_fecha_dependencia.columns:\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    sueldo_por_fecha_dependencia[dep].plot(kind='line')\n",
    "    plt.title(f'Suma de Sueldos por Fecha para {dep}')\n",
    "    plt.xlabel('Fecha')\n",
    "    plt.ylabel('Sueldo Total')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'img/sueldos_totales_por_fecha_{dep}.png')\n",
    "    plt.close()\n",
    "\n",
    "# Mostrar las gráficas en el entorno de Jupyter Notebook (si se está usando)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e43e804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afeaa222",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402d5166",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8cbfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Supongamos que el DataFrame df ya está cargado\n",
    "# df = pd.read_csv('csv/typed_itam.csv')\n",
    "# df['Fecha'] = pd.to_datetime(df['Fecha'])\n",
    "\n",
    "# Crear columnas de año y mes\n",
    "df['Año'] = df['Fecha'].dt.year\n",
    "df['Mes'] = df['Fecha'].dt.month\n",
    "\n",
    "\n",
    "# Gráfico de líneas para la suma de sueldos por mes a lo largo de los años\n",
    "plt.figure(figsize=(14, 7))\n",
    "sueldo_por_mes.T.plot(kind='line', title='Suma de Sueldos por Mes')\n",
    "plt.xlabel('Mes')\n",
    "plt.ylabel('Sueldo Total')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/suma_sueldos_por_mes.png')\n",
    "plt.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Estadísticas generales por dependencia\n",
    "dependencia_stats = df.groupby('dependencia')['Sueldo Neto'].describe()\n",
    "dependencia_stats = dependencia_stats.sort_values(by='count', ascending=False)\n",
    "\n",
    "# Estadísticas por año y mes\n",
    "sueldo_por_mes = df.groupby(['Año', 'Mes'])['Sueldo Neto'].sum().unstack()\n",
    "sueldo_promedio_por_mes = df.groupby(['Año', 'Mes'])['Sueldo Neto'].mean().unstack()\n",
    "\n",
    "# Top 10 dependencias con más y menos empleados\n",
    "top_10_dependencias_mas = dependencia_stats.head(10)\n",
    "top_10_dependencias_menos = dependencia_stats.tail(10)\n",
    "\n",
    "# Gráficos de barras para las 10 dependencias con más y menos empleados\n",
    "plt.figure(figsize=(14, 7))\n",
    "top_10_dependencias_mas['count'].plot(kind='bar', title='Top 10 Dependencias con Más Empleados')\n",
    "plt.xlabel('Dependencia')\n",
    "plt.ylabel('Número de Empleados')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/top_10_dependencias_mas.png')\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "top_10_dependencias_menos['count'].plot(kind='bar', title='Top 10 Dependencias con Menos Empleados')\n",
    "plt.xlabel('Dependencia')\n",
    "plt.ylabel('Número de Empleados')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/top_10_dependencias_menos.png')\n",
    "plt.close()\n",
    "\n",
    "# Gráfico de líneas para el promedio de sueldos por mes a lo largo de los años\n",
    "plt.figure(figsize=(14, 7))\n",
    "sueldo_promedio_por_mes.T.plot(kind='line', title='Promedio de Sueldos por Mes')\n",
    "plt.xlabel('Mes')\n",
    "plt.ylabel('Sueldo Promedio')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/promedio_sueldos_por_mes.png')\n",
    "plt.close()\n",
    "\n",
    "# Boxplot de sueldos por dependencia\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.boxplot(x='dependencia', y='Sueldo Neto', data=df, showfliers=False)\n",
    "plt.title('Distribución de Sueldos por Dependencia')\n",
    "plt.xlabel('Dependencia')\n",
    "plt.ylabel('Sueldo Neto')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/distribucion_sueldos_por_dependencia.png')\n",
    "plt.close()\n",
    "\n",
    "# Boxplot de sueldos por mes\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.boxplot(x='Mes', y='Sueldo Neto', data=df, showfliers=False)\n",
    "plt.title('Distribución de Sueldos por Mes')\n",
    "plt.xlabel('Mes')\n",
    "plt.ylabel('Sueldo Neto')\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/distribucion_sueldos_por_mes.png')\n",
    "plt.close()\n",
    "\n",
    "# Heatmap de la matriz de correlación entre dependencias\n",
    "pivot_table = df.pivot_table(index='Fecha', columns='dependencia', values='Sueldo Neto', aggfunc='sum')\n",
    "correlation_matrix = pivot_table.corr()\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.heatmap(correlation_matrix, cmap='coolwarm', annot=False)\n",
    "plt.title('Matriz de Correlación entre Dependencias')\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/matriz_correlacion_dependencias.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"Estadísticas descriptivas y gráficos generados exitosamente.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937439b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf74e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Supongamos que el DataFrame df ya está cargado\n",
    "# df = pd.read_csv('csv/typed_itam.csv')\n",
    "# df['Fecha'] = pd.to_datetime(df['Fecha'])\n",
    "\n",
    "# Crear columnas de año y mes\n",
    "df['Año'] = df['Fecha'].dt.year\n",
    "df['Mes'] = df['Fecha'].dt.month\n",
    "\n",
    "# Estadísticas generales por dependencia\n",
    "dependencia_stats = df.groupby('dependencia')['Sueldo Neto'].describe()\n",
    "dependencia_stats = dependencia_stats.sort_values(by='count', ascending=False)\n",
    "\n",
    "# Estadísticas por año y mes\n",
    "sueldo_por_mes = df.groupby(['Año', 'Mes'])['Sueldo Neto'].sum().unstack()\n",
    "sueldo_promedio_por_mes = df.groupby(['Año', 'Mes'])['Sueldo Neto'].mean().unstack()\n",
    "\n",
    "# Top 10 dependencias con más y menos empleados\n",
    "top_10_dependencias_mas = dependencia_stats.head(10)\n",
    "top_10_dependencias_menos = dependencia_stats.tail(10)\n",
    "\n",
    "# Gráficos de barras para las 10 dependencias con más y menos empleados\n",
    "plt.figure(figsize=(14, 7))\n",
    "top_10_dependencias_mas['count'].plot(kind='bar', title='Top 10 Dependencias con Más Empleados')\n",
    "plt.xlabel('Dependencia')\n",
    "plt.ylabel('Número de Empleados')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/top_10_dependencias_mas.png')\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "top_10_dependencias_menos['count'].plot(kind='bar', title='Top 10 Dependencias con Menos Empleados')\n",
    "plt.xlabel('Dependencia')\n",
    "plt.ylabel('Número de Empleados')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/top_10_dependencias_menos.png')\n",
    "plt.close()\n",
    "\n",
    "# Gráfico de líneas para la suma de sueldos por mes a lo largo de los años\n",
    "plt.figure(figsize=(14, 7))\n",
    "sueldo_por_mes.T.plot(kind='line', title='Suma de Sueldos por Mes')\n",
    "plt.xlabel('Mes')\n",
    "plt.ylabel('Sueldo Total')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/suma_sueldos_por_mes.png')\n",
    "plt.close()\n",
    "\n",
    "# Gráfico de líneas para el promedio de sueldos por mes a lo largo de los años\n",
    "plt.figure(figsize=(14, 7))\n",
    "sueldo_promedio_por_mes.T.plot(kind='line', title='Promedio de Sueldos por Mes')\n",
    "plt.xlabel('Mes')\n",
    "plt.ylabel('Sueldo Promedio')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/promedio_sueldos_por_mes.png')\n",
    "plt.close()\n",
    "\n",
    "# Boxplot de sueldos por dependencia\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.boxplot(x='dependencia', y='Sueldo Neto', data=df, showfliers=False)\n",
    "plt.title('Distribución de Sueldos por Dependencia')\n",
    "plt.xlabel('Dependencia')\n",
    "plt.ylabel('Sueldo Neto')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/distribucion_sueldos_por_dependencia.png')\n",
    "plt.close()\n",
    "\n",
    "# Boxplot de sueldos por mes\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.boxplot(x='Mes', y='Sueldo Neto', data=df, showfliers=False)\n",
    "plt.title('Distribución de Sueldos por Mes')\n",
    "plt.xlabel('Mes')\n",
    "plt.ylabel('Sueldo Neto')\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/distribucion_sueldos_por_mes.png')\n",
    "plt.close()\n",
    "\n",
    "# Heatmap de la matriz de correlación entre dependencias\n",
    "pivot_table = df.pivot_table(index='Fecha', columns='dependencia', values='Sueldo Neto', aggfunc='sum')\n",
    "correlation_matrix = pivot_table.corr()\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.heatmap(correlation_matrix, cmap='coolwarm', annot=False)\n",
    "plt.title('Matriz de Correlación entre Dependencias')\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/matriz_correlacion_dependencias.png')\n",
    "plt.close()\n",
    "\n",
    "# Gráficos de líneas para sueldos totales por fecha con mínimo, máximo y promedio\n",
    "sueldo_totales_por_fecha = df.groupby('Fecha')['Sueldo Neto'].agg(['sum', 'min', 'max', 'mean'])\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(sueldo_totales_por_fecha.index, sueldo_totales_por_fecha['sum'], label='Suma')\n",
    "plt.plot(sueldo_totales_por_fecha.index, sueldo_totales_por_fecha['min'], label='Mínimo')\n",
    "plt.plot(sueldo_totales_por_fecha.index, sueldo_totales_por_fecha['max'], label='Máximo')\n",
    "plt.plot(sueldo_totales_por_fecha.index, sueldo_totales_por_fecha['mean'], label='Promedio')\n",
    "plt.title('Sueldo Totales por Fecha')\n",
    "plt.xlabel('Fecha')\n",
    "plt.ylabel('Sueldo')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/sueldo_totales_por_fecha.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"Estadísticas descriptivas y gráficos generados exitosamente.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c09a76e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d5bddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Supongamos que el DataFrame df ya está cargado\n",
    "# df = pd.read_csv('csv/typed_itam.csv')\n",
    "# df['Fecha'] = pd.to_datetime(df['Fecha'])\n",
    "\n",
    "# Crear columnas de año y mes\n",
    "df['Año'] = df['Fecha'].dt.year\n",
    "df['Mes'] = df['Fecha'].dt.month\n",
    "\n",
    "# Estadísticas generales por dependencia\n",
    "dependencia_stats = df.groupby('dependencia')['Sueldo Neto'].describe()\n",
    "dependencia_stats = dependencia_stats.sort_values(by='count', ascending=False)\n",
    "\n",
    "# Estadísticas por año y mes\n",
    "sueldo_por_mes = df.groupby(['Año', 'Mes'])['Sueldo Neto'].sum().unstack()\n",
    "sueldo_promedio_por_mes = df.groupby(['Año', 'Mes'])['Sueldo Neto'].mean().unstack()\n",
    "\n",
    "# Top 10 dependencias con mayores sueldos totales acumulados\n",
    "top_10_dependencias_sueldos = df.groupby('dependencia')['Sueldo Neto'].sum().nlargest(10)\n",
    "\n",
    "# Gráficos de barras para las 10 dependencias con mayores sueldos totales acumulados\n",
    "plt.figure(figsize=(14, 7))\n",
    "top_10_dependencias_sueldos.plot(kind='bar', title='Top 10 Dependencias con Mayores Sueldos Totales Acumulados')\n",
    "plt.xlabel('Dependencia')\n",
    "plt.ylabel('Sueldo Total Acumulado')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/top_10_dependencias_sueldos.png')\n",
    "plt.close()\n",
    "\n",
    "# Gráficos de líneas para sueldos totales por mes a lo largo de los años\n",
    "plt.figure(figsize=(14, 7))\n",
    "sueldo_por_mes.T.plot(kind='line', title='Suma de Sueldos por Mes')\n",
    "plt.xlabel('Mes')\n",
    "plt.ylabel('Sueldo Total')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/suma_sueldos_por_mes.png')\n",
    "plt.close()\n",
    "\n",
    "# Gráficos de líneas para el promedio de sueldos por mes a lo largo de los años\n",
    "plt.figure(figsize=(14, 7))\n",
    "sueldo_promedio_por_mes.T.plot(kind='line', title='Promedio de Sueldos por Mes')\n",
    "plt.xlabel('Mes')\n",
    "plt.ylabel('Sueldo Promedio')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/promedio_sueldos_por_mes.png')\n",
    "plt.close()\n",
    "\n",
    "# Boxplot de sueldos por dependencia\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.boxplot(x='dependencia', y='Sueldo Neto', data=df[df['dependencia'].isin(top_10_dependencias_sueldos.index)], showfliers=False)\n",
    "plt.title('Distribución de Sueldos por Dependencia (Top 10)')\n",
    "plt.xlabel('Dependencia')\n",
    "plt.ylabel('Sueldo Neto')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/distribucion_sueldos_por_dependencia_top_10.png')\n",
    "plt.close()\n",
    "\n",
    "# Gráficos de líneas para las 10 dependencias con mayores sueldos totales acumulados\n",
    "for dep in top_10_dependencias_sueldos.index:\n",
    "    df_dep = df[df['dependencia'] == dep].groupby('Fecha')['Sueldo Neto'].sum()\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    df_dep.plot(kind='line', title=f'Suma de Sueldos por Fecha para {dep}')\n",
    "    plt.xlabel('Fecha')\n",
    "    plt.ylabel('Sueldo Total')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'img/sueldos_totales_por_fecha_{dep}.png')\n",
    "    plt.close()\n",
    "\n",
    "# Heatmap de la matriz de correlación entre las 30 dependencias con mayores sueldos totales acumulados\n",
    "top_30_dependencias_sueldos = df.groupby('dependencia')['Sueldo Neto'].sum().nlargest(30)\n",
    "for year in df['Año'].unique():\n",
    "    df_year = df[df['Año'] == year]\n",
    "    pivot_table = df_year[df_year['dependencia'].isin(top_30_dependencias_sueldos.index)].pivot_table(index='Fecha', columns='dependencia', values='Sueldo Neto', aggfunc='sum')\n",
    "    correlation_matrix = pivot_table.corr()\n",
    "\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    sns.heatmap(correlation_matrix, cmap='coolwarm', annot=False)\n",
    "    plt.title(f'Matriz de Correlación entre Dependencias (Top 30) en {year}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'img/matriz_correlacion_dependencias_top_30_{year}.png')\n",
    "    plt.close()\n",
    "\n",
    "# Gráficos de líneas para sueldos totales por fecha con mínimo, máximo y promedio\n",
    "sueldo_totales_por_fecha = df.groupby('Fecha')['Sueldo Neto'].agg(['sum', 'min', 'max', 'mean'])\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(sueldo_totales_por_fecha.index, sueldo_totales_por_fecha['sum'], label='Suma')\n",
    "plt.plot(sueldo_totales_por_fecha.index, sueldo_totales_por_fecha['min'], label='Mínimo')\n",
    "plt.plot(sueldo_totales_por_fecha.index, sueldo_totales_por_fecha['max'], label='Máximo')\n",
    "plt.plot(sueldo_totales_por_fecha.index, sueldo_totales_por_fecha['mean'], label='Promedio')\n",
    "plt.title('Sueldos Totales por Fecha')\n",
    "plt.xlabel('Fecha')\n",
    "plt.ylabel('Sueldo')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/sueldo_totales_por_fecha.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"Estadísticas descriptivas y gráficos generados exitosamente.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1123263",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44495fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Supongamos que el DataFrame df ya está cargado\n",
    "# df = pd.read_csv('csv/typed_itam.csv')\n",
    "# df['Fecha'] = pd.to_datetime(df['Fecha'])\n",
    "\n",
    "# Crear columnas de año y mes\n",
    "df['Año'] = df['Fecha'].dt.year\n",
    "df['Mes'] = df['Fecha'].dt.month\n",
    "\n",
    "# Estadísticas generales por dependencia\n",
    "dependencia_stats = df.groupby('dependencia')['Sueldo Neto'].describe()\n",
    "dependencia_stats = dependencia_stats.sort_values(by='count', ascending=False)\n",
    "\n",
    "# Estadísticas por año y mes\n",
    "sueldo_por_mes = df.groupby(['Año', 'Mes'])['Sueldo Neto'].sum().unstack()\n",
    "sueldo_promedio_por_mes = df.groupby(['Año', 'Mes'])['Sueldo Neto'].mean().unstack()\n",
    "\n",
    "# Top 10 dependencias con mayores sueldos totales acumulados\n",
    "top_10_dependencias_sueldos = df.groupby('dependencia')['Sueldo Neto'].sum().nlargest(10)\n",
    "\n",
    "# Gráficos de barras para las 10 dependencias con mayores sueldos totales acumulados\n",
    "plt.figure(figsize=(14, 7))\n",
    "top_10_dependencias_sueldos.plot(kind='bar', title='Top 10 Dependencias con Mayores Sueldos Totales Acumulados')\n",
    "plt.xlabel('Dependencia')\n",
    "plt.ylabel('Sueldo Total Acumulado')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/top_10_dependencias_sueldos.png')\n",
    "plt.close()\n",
    "\n",
    "# Gráficos de líneas para sueldos totales por mes a lo largo de los años\n",
    "plt.figure(figsize=(14, 7))\n",
    "sueldo_por_mes.T.plot(kind='line', title='Suma de Sueldos por Mes')\n",
    "plt.xlabel('Mes')\n",
    "plt.ylabel('Sueldo Total')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/suma_sueldos_por_mes.png')\n",
    "plt.close()\n",
    "\n",
    "# Gráficos de líneas para el promedio de sueldos por mes a lo largo de los años\n",
    "plt.figure(figsize=(14, 7))\n",
    "sueldo_promedio_por_mes.T.plot(kind='line', title='Promedio de Sueldos por Mes')\n",
    "plt.xlabel('Mes')\n",
    "plt.ylabel('Sueldo Promedio')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/promedio_sueldos_por_mes.png')\n",
    "plt.close()\n",
    "\n",
    "# Boxplot de sueldos por dependencia\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.boxplot(x='dependencia', y='Sueldo Neto', data=df[df['dependencia'].isin(top_10_dependencias_sueldos.index)], showfliers=False)\n",
    "plt.title('Distribución de Sueldos por Dependencia (Top 10)')\n",
    "plt.xlabel('Dependencia')\n",
    "plt.ylabel('Sueldo Neto')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/distribucion_sueldos_por_dependencia_top_10.png')\n",
    "plt.close()\n",
    "\n",
    "# Gráficos de líneas para las 10 dependencias con mayores sueldos totales acumulados\n",
    "for dep in top_10_dependencias_sueldos.index:\n",
    "    df_dep = df[df['dependencia'] == dep].groupby('Fecha')['Sueldo Neto'].sum()\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    df_dep.plot(kind='line', title=f'Suma de Sueldos por Fecha para {dep}')\n",
    "    plt.xlabel('Fecha')\n",
    "    plt.ylabel('Sueldo Total')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'img/sueldos_totales_por_fecha_{dep}.png')\n",
    "    plt.close()\n",
    "\n",
    "# Heatmap de la matriz de correlación entre las 30 dependencias con mayores sueldos totales acumulados\n",
    "top_30_dependencias_sueldos = df.groupby('dependencia')['Sueldo Neto'].sum().nlargest(30)\n",
    "for year in df['Año'].unique():\n",
    "    df_year = df[df['Año'] == year]\n",
    "    pivot_table = df_year[df_year['dependencia'].isin(top_30_dependencias_sueldos.index)].pivot_table(index='Fecha', columns='dependencia', values='Sueldo Neto', aggfunc='sum')\n",
    "    correlation_matrix = pivot_table.corr()\n",
    "\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    sns.heatmap(correlation_matrix, cmap='coolwarm', annot=False)\n",
    "    plt.title(f'Matriz de Correlación entre Dependencias (Top 30) en {year}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'img/matriz_correlacion_dependencias_top_30_{year}.png')\n",
    "    plt.close()\n",
    "\n",
    "# Gráficos de líneas para sueldos totales por fecha con mínimo, máximo y promedio\n",
    "sueldo_totales_por_fecha = df.groupby('Fecha')['Sueldo Neto'].agg(['sum', 'min', 'max', 'mean'])\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(sueldo_totales_por_fecha.index, sueldo_totales_por_fecha['sum'], label='Suma')\n",
    "plt.plot(sueldo_totales_por_fecha.index, sueldo_totales_por_fecha['min'], label='Mínimo')\n",
    "plt.plot(sueldo_totales_por_fecha.index, sueldo_totales_por_fecha['max'], label='Máximo')\n",
    "plt.plot(sueldo_totales_por_fecha.index, sueldo_totales_por_fecha['mean'], label='Promedio')\n",
    "plt.title('Sueldos Totales por Fecha')\n",
    "plt.xlabel('Fecha')\n",
    "plt.ylabel('Sueldo')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/sueldo_totales_por_fecha.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"Estadísticas descriptivas y gráficos generados exitosamente.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d89b08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5847815",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "# Supongamos que el DataFrame df ya está cargado\n",
    "# df = pd.read_csv('csv/typed_itam.csv')\n",
    "# df['Fecha'] = pd.to_datetime(df['Fecha'])\n",
    "\n",
    "# Crear columnas de año y mes\n",
    "df['Año'] = df['Fecha'].dt.year\n",
    "df['Mes'] = df['Fecha'].dt.month\n",
    "\n",
    "# Estadísticas generales por dependencia\n",
    "dependencia_stats = df.groupby('dependencia')['Sueldo Neto'].describe()\n",
    "dependencia_stats = dependencia_stats.sort_values(by='count', ascending=False)\n",
    "\n",
    "# Estadísticas por año y mes\n",
    "sueldo_por_mes = df.groupby(['Año', 'Mes'])['Sueldo Neto'].sum().unstack()\n",
    "sueldo_promedio_por_mes = df.groupby(['Año', 'Mes'])['Sueldo Neto'].mean().unstack()\n",
    "\n",
    "# Top 10 dependencias con mayores sueldos totales acumulados\n",
    "top_10_dependencias_sueldos = df.groupby('dependencia')['Sueldo Neto'].sum().nlargest(10)\n",
    "\n",
    "# Gráficos de barras para las 10 dependencias con mayores sueldos totales acumulados\n",
    "plt.figure(figsize=(14, 7))\n",
    "top_10_dependencias_sueldos.plot(kind='bar', title='Top 10 Dependencias con Mayores Sueldos Totales Acumulados')\n",
    "plt.xlabel('Dependencia')\n",
    "plt.ylabel('Sueldo Total Acumulado')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/top_10_dependencias_sueldos.png')\n",
    "plt.close()\n",
    "\n",
    "# Gráficos de líneas para sueldos totales por mes a lo largo de los años\n",
    "plt.figure(figsize=(14, 7))\n",
    "ax = sueldo_por_mes.T.plot(kind='line', title='Suma de Sueldos por Mes')\n",
    "ax.set_xlabel('Mes')\n",
    "ax.set_ylabel('Sueldo Total')\n",
    "ax.xaxis.set_major_locator(ticker.MaxNLocator(integer=True))\n",
    "ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x)))\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/suma_sueldos_por_mes.png')\n",
    "plt.close()\n",
    "\n",
    "# Gráficos de líneas para el promedio de sueldos por mes a lo largo de los años\n",
    "plt.figure(figsize=(14, 7))\n",
    "ax = sueldo_promedio_por_mes.T.plot(kind='line', title='Promedio de Sueldos por Mes')\n",
    "ax.set_xlabel('Mes')\n",
    "ax.set_ylabel('Sueldo Promedio')\n",
    "ax.xaxis.set_major_locator(ticker.MaxNLocator(integer=True))\n",
    "ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x)))\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/promedio_sueldos_por_mes.png')\n",
    "plt.close()\n",
    "\n",
    "# Boxplot de sueldos por dependencia\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.boxplot(x='dependencia', y='Sueldo Neto', data=df[df['dependencia'].isin(top_10_dependencias_sueldos.index)], showfliers=False)\n",
    "plt.title('Distribución de Sueldos por Dependencia (Top 10)')\n",
    "plt.xlabel('Dependencia')\n",
    "plt.ylabel('Sueldo Neto')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/distribucion_sueldos_por_dependencia_top_10.png')\n",
    "plt.close()\n",
    "\n",
    "# Gráficos de líneas para las 10 dependencias con mayores sueldos totales acumulados\n",
    "for dep in top_10_dependencias_sueldos.index:\n",
    "    df_dep = df[df['dependencia'] == dep].groupby('Fecha')['Sueldo Neto'].sum()\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    ax = df_dep.plot(kind='line', title=f'Suma de Sueldos por Fecha para {dep}')\n",
    "    ax.set_xlabel('Fecha')\n",
    "    ax.set_ylabel('Sueldo Total')\n",
    "    ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x)))\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'img/sueldos_totales_por_fecha_{dep}.png')\n",
    "    plt.close()\n",
    "\n",
    "# Heatmap de la matriz de correlación entre las 10 dependencias con mayores sueldos totales acumulados\n",
    "top_10_dependencias_sueldos = df.groupby('dependencia')['Sueldo Neto'].sum().nlargest(10)\n",
    "for year in df['Año'].unique():\n",
    "    df_year = df[df['Año'] == year]\n",
    "    pivot_table = df_year[df_year['dependencia'].isin(top_10_dependencias_sueldos.index)].pivot_table(index='Fecha', columns='dependencia', values='Sueldo Neto', aggfunc='sum')\n",
    "    correlation_matrix = pivot_table.corr()\n",
    "\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    sns.heatmap(correlation_matrix, cmap='coolwarm', annot=False)\n",
    "    plt.title(f'Matriz de Correlación entre Dependencias (Top 10) en {year}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'img/matriz_correlacion_dependencias_top_10_{year}.png')\n",
    "    plt.close()\n",
    "\n",
    "# Gráficos de líneas para sueldos totales por fecha con mínimo, máximo y promedio\n",
    "sueldo_totales_por_fecha = df.groupby('Fecha')['Sueldo Neto'].agg(['sum'])\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(sueldo_totales_por_fecha.index, sueldo_totales_por_fecha['sum'], label='Suma')\n",
    "plt.title('Sueldos Totales por Fecha')\n",
    "plt.xlabel('Fecha')\n",
    "plt.ylabel('Sueldo')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.gca().yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x)))\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/sueldo_totales_por_fecha.png')\n",
    "plt.close()\n",
    "\n",
    "# Gráfica de barras de las 5 dependencias con mayores sueldos netos totales acumulados por año\n",
    "top_5_dependencias_sueldos = df.groupby('dependencia')['Sueldo Neto'].sum().nlargest(5)\n",
    "df_top_5_anual = df[df['dependencia'].isin(top_5_dependencias_sueldos.index)].groupby(['Año', 'dependencia'])['Sueldo Neto'].sum().unstack()\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "df_top_5_anual.plot(kind='bar', stacked=True)\n",
    "plt.title('Top 5 Dependencias con Mayores Sueldos Netos Totales Acumulados por Año')\n",
    "plt.xlabel('Año')\n",
    "plt.ylabel('Sueldo Total Acumulado')\n",
    "plt.gca().yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x)))\n",
    "plt.legend(title='Dependencia')\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/top_5_dependencias_anual.png')\n",
    "plt.close()\n",
    "\n",
    "# Gráfica de pastel por año para las dependencias con mayores sueldos netos totales\n",
    "for year in df['Año'].unique():\n",
    "    df_year = df[df['Año'] == year]\n",
    "    top_10_dependencias_anual = df_year.groupby('dependencia')['Sueldo Neto'].sum().nlargest(10)\n",
    "\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    top_10_dependencias_anual.plot(kind='pie', autopct='%1.1f%%', startangle=140)\n",
    "    plt.title(f'Dependencias con Mayores Sueldos Netos Totales en {year}')\n",
    "    plt.ylabel('')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'img/dependencias_mayores_sueldos_netos_{year}.png')\n",
    "    plt.close()\n",
    "\n",
    "print(\"Estadísticas descriptivas y gráficos generados exitosamente.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfde11af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2198d2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "# Supongamos que el DataFrame df ya está cargado\n",
    "# df = pd.read_csv('csv/typed_itam.csv')\n",
    "# df['Fecha'] = pd.to_datetime(df['Fecha'])\n",
    "\n",
    "# Crear columnas de año y mes\n",
    "df['Año'] = df['Fecha'].dt.year\n",
    "df['Mes'] = df['Fecha'].dt.month\n",
    "\n",
    "# Estadísticas generales por tipo\n",
    "tipo_stats = df.groupby('Tipo')['Sueldo Neto'].describe()\n",
    "tipo_stats = tipo_stats.sort_values(by='count', ascending=False)\n",
    "\n",
    "# Estadísticas por año y mes\n",
    "sueldo_por_mes = df.groupby(['Año', 'Mes'])['Sueldo Neto'].sum().unstack()\n",
    "sueldo_promedio_por_mes = df.groupby(['Año', 'Mes'])['Sueldo Neto'].mean().unstack()\n",
    "\n",
    "# Top 10 tipos con mayores sueldos totales acumulados\n",
    "top_10_tipos_sueldos = df.groupby('Tipo')['Sueldo Neto'].sum().nlargest(10)\n",
    "\n",
    "# Gráficos de barras para las 10 tipos con mayores sueldos totales acumulados\n",
    "plt.figure(figsize=(14, 7))\n",
    "top_10_tipos_sueldos.plot(kind='bar', title='Top 10 Tipos con Mayores Sueldos Totales Acumulados')\n",
    "plt.xlabel('Tipo')\n",
    "plt.ylabel('Sueldo Total Acumulado')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/top_10_tipos_sueldos.png')\n",
    "plt.close()\n",
    "\n",
    "# Gráficos de líneas para sueldos totales por mes a lo largo de los años\n",
    "plt.figure(figsize=(14, 7))\n",
    "ax = sueldo_por_mes.T.plot(kind='line', title='Suma de Sueldos por Mes')\n",
    "ax.set_xlabel('Mes')\n",
    "ax.set_ylabel('Sueldo Total')\n",
    "ax.xaxis.set_major_locator(ticker.MaxNLocator(integer=True))\n",
    "ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x)))\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/suma_sueldos_por_mes.png')\n",
    "plt.close()\n",
    "\n",
    "# Gráficos de líneas para el promedio de sueldos por mes a lo largo de los años\n",
    "plt.figure(figsize=(14, 7))\n",
    "ax = sueldo_promedio_por_mes.T.plot(kind='line', title='Promedio de Sueldos por Mes')\n",
    "ax.set_xlabel('Mes')\n",
    "ax.set_ylabel('Sueldo Promedio')\n",
    "ax.xaxis.set_major_locator(ticker.MaxNLocator(integer=True))\n",
    "ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x)))\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/promedio_sueldos_por_mes.png')\n",
    "plt.close()\n",
    "\n",
    "# Boxplot de sueldos por tipo\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.boxplot(x='Tipo', y='Sueldo Neto', data=df[df['Tipo'].isin(top_10_tipos_sueldos.index)], showfliers=False)\n",
    "plt.title('Distribución de Sueldos por Tipo (Top 10)')\n",
    "plt.xlabel('Tipo')\n",
    "plt.ylabel('Sueldo Neto')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/distribucion_sueldos_por_tipo_top_10.png')\n",
    "plt.close()\n",
    "\n",
    "# Gráficos de líneas para los 10 tipos con mayores sueldos totales acumulados\n",
    "for tipo in top_10_tipos_sueldos.index:\n",
    "    df_tipo = df[df['Tipo'] == tipo].groupby('Fecha')['Sueldo Neto'].sum()\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    ax = df_tipo.plot(kind='line', title=f'Suma de Sueldos por Fecha para {tipo}')\n",
    "    ax.set_xlabel('Fecha')\n",
    "    ax.set_ylabel('Sueldo Total')\n",
    "    ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x)))\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'img/sueldos_totales_por_fecha_{tipo}.png')\n",
    "    plt.close()\n",
    "\n",
    "# Heatmap de la matriz de correlación entre los 10 tipos con mayores sueldos totales acumulados\n",
    "top_10_tipos_sueldos = df.groupby('Tipo')['Sueldo Neto'].sum().nlargest(10)\n",
    "for year in df['Año'].unique():\n",
    "    df_year = df[df['Año'] == year]\n",
    "    pivot_table = df_year[df_year['Tipo'].isin(top_10_tipos_sueldos.index)].pivot_table(index='Fecha', columns='Tipo', values='Sueldo Neto', aggfunc='sum')\n",
    "    correlation_matrix = pivot_table.corr()\n",
    "\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    sns.heatmap(correlation_matrix, cmap='coolwarm', annot=False)\n",
    "    plt.title(f'Matriz de Correlación entre Tipos (Top 10) en {year}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'img/matriz_correlacion_tipos_top_10_{year}.png')\n",
    "    plt.close()\n",
    "\n",
    "# Gráficos de líneas para sueldos totales por fecha con mínimo, máximo y promedio\n",
    "sueldo_totales_por_fecha = df.groupby('Fecha')['Sueldo Neto'].agg(['sum', 'min', 'max', 'mean'])\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(sueldo_totales_por_fecha.index, sueldo_totales_por_fecha['sum'], label='Suma')\n",
    "plt.plot(sueldo_totales_por_fecha.index, sueldo_totales_por_fecha['min'], label='Mínimo')\n",
    "plt.plot(sueldo_totales_por_fecha.index, sueldo_totales_por_fecha['max'], label='Máximo')\n",
    "plt.plot(sueldo_totales_por_fecha.index, sueldo_totales_por_fecha['mean'], label='Promedio')\n",
    "plt.title('Sueldos Totales por Fecha')\n",
    "plt.xlabel('Fecha')\n",
    "plt.ylabel('Sueldo')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.gca().yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x)))\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/sueldo_totales_por_fecha.png')\n",
    "plt.close()\n",
    "\n",
    "# Gráfica de barras de los 5 tipos con mayores sueldos netos totales acumulados por año\n",
    "top_5_tipos_sueldos = df.groupby('Tipo')['Sueldo Neto'].sum().nlargest(5)\n",
    "df_top_5_anual = df[df['Tipo'].isin(top_5_tipos_sueldos.index)].groupby(['Año', 'Tipo'])['Sueldo Neto'].sum().unstack()\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "df_top_5_anual.plot(kind='bar', stacked=True)\n",
    "plt.title('Top 5 Tipos con Mayores Sueldos Netos Totales Acumulados por Año')\n",
    "plt.xlabel('Año')\n",
    "plt.ylabel('Sueldo Total Acumulado')\n",
    "plt.gca().yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x)))\n",
    "plt.legend(title='Tipo')\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/top_5_tipos_anual.png')\n",
    "plt.close()\n",
    "\n",
    "# Gráfica de pastel por año para los tipos con mayores sueldos netos totales\n",
    "for year in df['Año'].unique():\n",
    "    df_year = df[df['Año'] == year]\n",
    "    top_10_tipos_anual = df_year.groupby('Tipo')['Sueldo Neto'].sum().nlargest(10)\n",
    "\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    top_10_tipos_anual.plot(kind='pie', autopct='%1.1f%%', startangle=140)\n",
    "    plt.title(f'Tipos con Mayores Sueldos Netos Totales en {year}')\n",
    "    plt.ylabel('')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'img/tipos_mayores_sueldos_netos_{year}.png')\n",
    "    plt.close()\n",
    "\n",
    "print(\"Estadísticas descriptivas y gráficos generados exitosamente.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cae61c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a834a37b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef5cb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as ticker\n",
    "from scipy.stats import shapiro, f_oneway, ttest_ind, kruskal\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Supongamos que el DataFrame df ya está cargado\n",
    "# df = pd.read_csv('csv/typed_itam.csv')\n",
    "# df['Fecha'] = pd.to_datetime(df['Fecha'])\n",
    "\n",
    "# Crear columnas de año y mes\n",
    "df['Año'] = df['Fecha'].dt.year\n",
    "df['Mes'] = df['Fecha'].dt.month\n",
    "\n",
    "# Estadísticas generales por tipo\n",
    "tipo_stats = df.groupby('Tipo')['Sueldo Neto'].describe()\n",
    "tipo_stats = tipo_stats.sort_values(by='count', ascending=False)\n",
    "\n",
    "# Estadísticas por año y mes\n",
    "sueldo_por_mes = df.groupby(['Año', 'Mes'])['Sueldo Neto'].sum().unstack()\n",
    "sueldo_promedio_por_mes = df.groupby(['Año', 'Mes'])['Sueldo Neto'].mean().unstack()\n",
    "\n",
    "# Top 10 tipos con mayores sueldos totales acumulados\n",
    "top_10_tipos_sueldos = df.groupby('Tipo')['Sueldo Neto'].sum().nlargest(10)\n",
    "\n",
    "# Gráficos de barras para los 10 tipos con mayores sueldos totales acumulados\n",
    "plt.figure(figsize=(14, 7))\n",
    "top_10_tipos_sueldos.plot(kind='bar', title='Top 10 Tipos con Mayores Sueldos Totales Acumulados')\n",
    "plt.xlabel('Tipo')\n",
    "plt.ylabel('Sueldo Total Acumulado')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/top_10_tipos_sueldos.png')\n",
    "plt.close()\n",
    "\n",
    "# Verificar la normalidad de las muestras por tipo\n",
    "normalidad = df.groupby('Tipo')['Sueldo Neto'].apply(lambda x: shapiro(x)[1] if len(x) >= 3 else np.nan)\n",
    "print(\"Resultados de normalidad (p-values):\\n\", normalidad)\n",
    "\n",
    "# Tipos con datos suficientes para ANOVA o Kruskal-Wallis\n",
    "tipos_validos = normalidad.dropna().index\n",
    "\n",
    "# Filtrar el DataFrame para los tipos válidos\n",
    "df_validos = df[df['Tipo'].isin(tipos_validos)]\n",
    "\n",
    "# Prueba ANOVA si todas las muestras son normales\n",
    "anova_resultados = f_oneway(*[df_validos[df_validos['Tipo'] == tipo]['Sueldo Neto'] for tipo in tipos_validos])\n",
    "print('Resultados de ANOVA:', anova_resultados)\n",
    "\n",
    "if anova_resultados.pvalue < 0.05:\n",
    "    print(\"Existen diferencias significativas entre los tipos. Proceder con pruebas adicionales.\")\n",
    "    ttest_resultados = {}\n",
    "    for i in range(len(tipos_validos)):\n",
    "        for j in range(i+1, len(tipos_validos)):\n",
    "            tipo1 = tipos_validos[i]\n",
    "            tipo2 = tipos_validos[j]\n",
    "            ttest_resultados[f'{tipo1} vs {tipo2}'] = ttest_ind(df_validos[df_validos['Tipo'] == tipo1]['Sueldo Neto'],\n",
    "                                                                df_validos[df_validos['Tipo'] == tipo2]['Sueldo Neto'])\n",
    "    print(ttest_resultados)\n",
    "else:\n",
    "    print(\"No existen diferencias significativas entre los tipos según ANOVA.\")\n",
    "\n",
    "# Prueba Kruskal-Wallis si alguna muestra no es normal\n",
    "kruskal_resultados = kruskal(*[df_validos[df_validos['Tipo'] == tipo]['Sueldo Neto'] for tipo in tipos_validos])\n",
    "print('Resultados de Kruskal-Wallis:', kruskal_resultados)\n",
    "\n",
    "if kruskal_resultados.pvalue < 0.05:\n",
    "    print(\"Existen diferencias significativas entre los tipos. Proceder con prueba de Tukey.\")\n",
    "    tukey_resultados = pairwise_tukeyhsd(df_validos['Sueldo Neto'], df_validos['Tipo'])\n",
    "    print(tukey_resultados)\n",
    "else:\n",
    "    print(\"No existen diferencias significativas entre los tipos según Kruskal-Wallis.\")\n",
    "\n",
    "# Gráficos de líneas para sueldos totales por mes a lo largo de los años\n",
    "plt.figure(figsize=(14, 7))\n",
    "ax = sueldo_por_mes.T.plot(kind='line', title='Suma de Sueldos por Mes')\n",
    "ax.set_xlabel('Mes')\n",
    "ax.set_ylabel('Sueldo Total')\n",
    "ax.xaxis.set_major_locator(ticker.MaxNLocator(integer=True))\n",
    "ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x)))\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/suma_sueldos_por_mes.png')\n",
    "plt.close()\n",
    "\n",
    "# Gráficos de líneas para el promedio de sueldos por mes a lo largo de los años\n",
    "plt.figure(figsize=(14, 7))\n",
    "ax = sueldo_promedio_por_mes.T.plot(kind='line', title='Promedio de Sueldos por Mes')\n",
    "ax.set_xlabel('Mes')\n",
    "ax.set_ylabel('Sueldo Promedio')\n",
    "ax.xaxis.set_major_locator(ticker.MaxNLocator(integer=True))\n",
    "ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x)))\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/promedio_sueldos_por_mes.png')\n",
    "plt.close()\n",
    "\n",
    "# Boxplot de sueldos por tipo\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.boxplot(x='Tipo', y='Sueldo Neto', data=df[df['Tipo'].isin(top_10_tipos_sueldos.index)], showfliers=False)\n",
    "plt.title('Distribución de Sueldos por Tipo (Top 10)')\n",
    "plt.xlabel('Tipo')\n",
    "plt.ylabel('Sueldo Neto')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/distribucion_sueldos_por_tipo_top_10.png')\n",
    "plt.close()\n",
    "\n",
    "# Gráficos de líneas para los 10 tipos con mayores sueldos totales acumulados\n",
    "for tipo in top_10_tipos_sueldos.index:\n",
    "    df_tipo = df[df['Tipo'] == tipo].groupby('Fecha')['Sueldo Neto'].sum()\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    ax = df_tipo.plot(kind='line', title=f'Suma de Sueldos por Fecha para {tipo}')\n",
    "    ax.set_xlabel('Fecha')\n",
    "    ax.set_ylabel('Sueldo Total')\n",
    "    ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x)))\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'img/sueldos_totales_por_fecha_{tipo}.png')\n",
    "    plt.close()\n",
    "\n",
    "# Heatmap de la matriz de correlación entre los 10 tipos con mayores sueldos totales acumulados\n",
    "top_10_tipos_sueldos = df.groupby('Tipo')['Sueldo Neto'].sum().nlargest(10)\n",
    "for year in df['Año'].unique():\n",
    "    df_year = df[df['Año'] == year]\n",
    "    pivot_table = df_year[df_year['Tipo'].isin(top_10_tipos_sueldos.index)].pivot_table(index='Fecha', columns='Tipo', values='Sueldo Neto', aggfunc='sum')\n",
    "    correlation_matrix = pivot_table.corr()\n",
    "\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    sns.heatmap(correlation_matrix, cmap='coolwarm', annot=False)\n",
    "    plt.title(f'Matriz de Correlación entre Tipos (Top 10) en {year}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'img/matriz_correlacion_tipos_top_10_{year}.png')\n",
    "    plt.close()\n",
    "\n",
    "# Gráficos de líneas para sueldos totales por fecha con mínimo, máximo y promedio\n",
    "sueldo_totales_por_fecha = df.groupby('Fecha')['Sueldo Neto'].agg(['sum', 'min', 'max', 'mean'])\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(sueldo_totales_por_fecha.index, sueldo_totales_por_fecha['sum'], label='Suma')\n",
    "plt.plot(sueldo_totales_por_fecha.index, sueldo_totales_por_fecha['min'], label='Mínimo')\n",
    "plt.plot(sueldo_totales_por_fecha.index, sueldo_totales_por_fecha['max'], label='Máximo')\n",
    "plt.plot(sueldo_totales_por_fecha.index, sueldo_totales_por_fecha['mean'], label='Promedio')\n",
    "plt.title('Sueldos Totales por Fecha')\n",
    "plt.xlabel('Fecha')\n",
    "plt.ylabel('Sueldo')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.gca().yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x)))\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/sueldo_totales_por_fecha.png')\n",
    "plt.close()\n",
    "\n",
    "# Gráfica de barras de los 5 tipos con mayores sueldos netos totales acumulados por año\n",
    "top_5_tipos_sueldos = df.groupby('Tipo')['Sueldo Neto'].sum().nlargest(5)\n",
    "df_top_5_anual = df[df['Tipo'].isin(top_5_tipos_sueldos.index)].groupby(['Año', 'Tipo'])['Sueldo Neto'].sum().unstack()\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "df_top_5_anual.plot(kind='bar', stacked=True)\n",
    "plt.title('Top 5 Tipos con Mayores Sueldos Netos Totales Acumulados por Año')\n",
    "plt.xlabel('Año')\n",
    "plt.ylabel('Sueldo Total Acumulado')\n",
    "plt.gca().yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x)))\n",
    "plt.legend(title='Tipo')\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/top_5_tipos_anual.png')\n",
    "plt.close()\n",
    "\n",
    "# Gráfica de pastel por año para los tipos con mayores sueldos netos totales\n",
    "for year in df['Año'].unique():\n",
    "    df_year = df[df['Año'] == year]\n",
    "    top_10_tipos_anual = df_year.groupby('Tipo')['Sueldo Neto'].sum().nlargest(10)\n",
    "\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    top_10_tipos_anual.plot(kind='pie', autopct='%1.1f%%', startangle=140)\n",
    "    plt.title(f'Tipos con Mayores Sueldos Netos Totales en {year}')\n",
    "    plt.ylabel('')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'img/tipos_mayores_sueldos_netos_{year}.png')\n",
    "    plt.close()\n",
    "\n",
    "print(\"Estadísticas descriptivas y gráficos generados exitosamente.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b64054",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1967b243",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cb3d9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad4968e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4b58b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import shapiro, f_oneway, ttest_ind, kruskal, norm, lognorm, expon\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Supongamos que el DataFrame df ya está cargado\n",
    "# df = pd.read_csv('csv/typed_itam.csv')\n",
    "# df['Fecha'] = pd.to_datetime(df['Fecha'])\n",
    "\n",
    "# Crear columnas de año y mes\n",
    "df['Año'] = df['Fecha'].dt.year\n",
    "df['Mes'] = df['Fecha'].dt.month\n",
    "\n",
    "# Filtrar los tipos con suficientes datos\n",
    "tipos_validos = df['Tipo'].unique()\n",
    "\n",
    "# Función para ajustar distribuciones\n",
    "def fit_distributions(data):\n",
    "    dist_names = ['norm', 'lognorm', 'expon']\n",
    "    dist_results = {}\n",
    "    for dist_name in dist_names:\n",
    "        dist = getattr(__import__('scipy.stats', fromlist=[dist_name]), dist_name)\n",
    "        params = dist.fit(data)\n",
    "        dist_results[dist_name] = params\n",
    "    return dist_results\n",
    "\n",
    "# Pruebas ANOVA y Kruskal-Wallis por mes\n",
    "resultados_anova = {}\n",
    "resultados_kruskal = {}\n",
    "distribuciones = {}\n",
    "\n",
    "for year in df['Año'].unique():\n",
    "    for month in df['Mes'].unique():\n",
    "        df_month = df[(df['Año'] == year) & (df['Mes'] == month)]\n",
    "        \n",
    "        if df_month.empty:\n",
    "            continue\n",
    "        \n",
    "        normalidad = df_month.groupby('Tipo')['Sueldo Neto'].apply(lambda x: shapiro(x)[1] if len(x) >= 3 else np.nan)\n",
    "        tipos_validos_mes = normalidad.dropna().index\n",
    "        df_validos_mes = df_month[df_month['Tipo'].isin(tipos_validos_mes)]\n",
    "        \n",
    "        if df_validos_mes.empty:\n",
    "            continue\n",
    "        \n",
    "        # Prueba ANOVA si todas las muestras son normales\n",
    "        if all(normalidad.dropna() > 0.05):\n",
    "            anova_resultados = f_oneway(*[df_validos_mes[df_validos_mes['Tipo'] == tipo]['Sueldo Neto'] for tipo in tipos_validos_mes])\n",
    "            resultados_anova[(year, month)] = anova_resultados\n",
    "            if anova_resultados.pvalue < 0.05:\n",
    "                ttest_resultados = {}\n",
    "                for i in range(len(tipos_validos_mes)):\n",
    "                    for j in range(i+1, len(tipos_validos_mes)):\n",
    "                        tipo1 = tipos_validos_mes[i]\n",
    "                        tipo2 = tipos_validos_mes[j]\n",
    "                        ttest_resultados[f'{tipo1} vs {tipo2}'] = ttest_ind(df_validos_mes[df_validos_mes['Tipo'] == tipo1]['Sueldo Neto'],\n",
    "                                                                            df_validos_mes[df_validos_mes['Tipo'] == tipo2]['Sueldo Neto'])\n",
    "                print(f\"Resultados de t-test para {year}-{month}:\\n\", ttest_resultados)\n",
    "        else:\n",
    "            kruskal_resultados = kruskal(*[df_validos_mes[df_validos_mes['Tipo'] == tipo]['Sueldo Neto'] for tipo in tipos_validos_mes])\n",
    "            resultados_kruskal[(year, month)] = kruskal_resultados\n",
    "            if kruskal_resultados.pvalue < 0.05:\n",
    "                tukey_resultados = pairwise_tukeyhsd(df_validos_mes['Sueldo Neto'], df_validos_mes['Tipo'])\n",
    "                print(f\"Resultados de Tukey para {year}-{month}:\\n\", tukey_resultados)\n",
    "                \n",
    "                distribuciones[(year, month)] = {}\n",
    "                for tipo in tipos_validos_mes:\n",
    "                    data = df_validos_mes[df_validos_mes['Tipo'] == tipo]['Sueldo Neto']\n",
    "                    distribuciones[(year, month)][tipo] = fit_distributions(data)\n",
    "                print(f\"Distribuciones ajustadas para {year}-{month}:\\n\", distribuciones[(year, month)])\n",
    "\n",
    "print(\"Resultados de ANOVA:\\n\", resultados_anova)\n",
    "print(\"Resultados de Kruskal-Wallis:\\n\", resultados_kruskal)\n",
    "print(\"Distribuciones ajustadas:\\n\", distribuciones)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34825cd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89af9e11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5458a76f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b657c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import shapiro, f_oneway, ttest_ind, kruskal, norm, lognorm, expon, weibull_min, gamma, f\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Supongamos que el DataFrame df ya está cargado\n",
    "# df = pd.read_csv('csv/typed_itam.csv')\n",
    "# df['Fecha'] = pd.to_datetime(df['Fecha'])\n",
    "\n",
    "# Crear columna de año\n",
    "df['Año'] = df['Fecha'].dt.year\n",
    "\n",
    "# Función para ajustar distribuciones\n",
    "def fit_distributions(data):\n",
    "    dist_names = ['norm', 'lognorm', 'expon', 'weibull_min', 'gamma', 'f']\n",
    "    dist_results = {}\n",
    "    for dist_name in dist_names:\n",
    "        dist = getattr(__import__('scipy.stats', fromlist=[dist_name]), dist_name)\n",
    "        params = dist.fit(data)\n",
    "        dist_results[dist_name] = params\n",
    "    return dist_results\n",
    "\n",
    "# Pruebas ANOVA y Kruskal-Wallis por año\n",
    "resultados_anova = {}\n",
    "resultados_kruskal = {}\n",
    "distribuciones = {}\n",
    "\n",
    "for year in df['Año'].unique():\n",
    "    df_year = df[df['Año'] == year]\n",
    "    \n",
    "    if df_year.empty:\n",
    "        continue\n",
    "    \n",
    "    normalidad = df_year.groupby('Tipo')['Sueldo Neto'].apply(lambda x: shapiro(x)[1] if len(x) >= 3 else np.nan)\n",
    "    tipos_validos = normalidad.dropna().index\n",
    "    df_validos = df_year[df_year['Tipo'].isin(tipos_validos)]\n",
    "    \n",
    "    if df_validos.empty:\n",
    "        continue\n",
    "    \n",
    "    # Prueba ANOVA si todas las muestras son normales\n",
    "    if all(normalidad.dropna() > 0.05):\n",
    "        anova_resultados = f_oneway(*[df_validos[df_validos['Tipo'] == tipo]['Sueldo Neto'] for tipo in tipos_validos])\n",
    "        resultados_anova[year] = anova_resultados\n",
    "        if anova_resultados.pvalue < 0.05:\n",
    "            ttest_resultados = {}\n",
    "            for i in range(len(tipos_validos)):\n",
    "                for j in range(i+1, len(tipos_validos)):\n",
    "                    tipo1 = tipos_validos[i]\n",
    "                    tipo2 = tipos_validos[j]\n",
    "                    ttest_resultados[f'{tipo1} vs {tipo2}'] = ttest_ind(df_validos[df_validos['Tipo'] == tipo1]['Sueldo Neto'],\n",
    "                                                                        df_validos[df_validos['Tipo'] == tipo2]['Sueldo Neto'])\n",
    "            print(f\"Resultados de t-test para {year}:\\n\", ttest_resultados)\n",
    "    else:\n",
    "        kruskal_resultados = kruskal(*[df_validos[df_validos['Tipo'] == tipo]['Sueldo Neto'] for tipo in tipos_validos])\n",
    "        resultados_kruskal[year] = kruskal_resultados\n",
    "        if kruskal_resultados.pvalue < 0.05:\n",
    "            tukey_resultados = pairwise_tukeyhsd(df_validos['Sueldo Neto'], df_validos['Tipo'])\n",
    "            print(f\"Resultados de Tukey para {year}:\\n\", tukey_resultados)\n",
    "            \n",
    "            distribuciones[year] = {}\n",
    "            for tipo in tipos_validos:\n",
    "                data = df_validos[df_validos['Tipo'] == tipo]['Sueldo Neto']\n",
    "                distribuciones[year][tipo] = fit_distributions(data)\n",
    "            print(f\"Distribuciones ajustadas para {year}:\\n\", distribuciones[year])\n",
    "\n",
    "print(\"Resultados de ANOVA:\\n\", resultados_anova)\n",
    "print(\"Resultados de Kruskal-Wallis:\\n\", resultados_kruskal)\n",
    "print(\"Distribuciones ajustadas:\\n\", distribuciones)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c967ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c9db33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7086ed44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import shapiro, f_oneway, ttest_ind, kruskal, norm, lognorm, expon, weibull_min, gamma, f\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Supongamos que el DataFrame df ya está cargado\n",
    "# df = pd.read_csv('csv/typed_itam.csv')\n",
    "# df['Fecha'] = pd.to_datetime(df['Fecha'])\n",
    "\n",
    "# Crear columna de año\n",
    "df['Año'] = df['Fecha'].dt.year\n",
    "\n",
    "# Función para ajustar distribuciones\n",
    "def fit_distributions(data):\n",
    "    dist_names = ['norm', 'lognorm', 'expon', 'weibull_min', 'gamma', 'f']\n",
    "    dist_results = {}\n",
    "    for dist_name in dist_names:\n",
    "        dist = getattr(__import__('scipy.stats', fromlist=[dist_name]), dist_name)\n",
    "        params = dist.fit(data)\n",
    "        dist_results[dist_name] = params\n",
    "    return dist_results\n",
    "\n",
    "# Pruebas ANOVA y Kruskal-Wallis por año\n",
    "resultados_anova = {}\n",
    "resultados_kruskal = {}\n",
    "distribuciones = {}\n",
    "\n",
    "for year in df['Año'].unique():\n",
    "    df_year = df[df['Año'] == year]\n",
    "    \n",
    "    if df_year.empty:\n",
    "        continue\n",
    "    \n",
    "    normalidad = df_year.groupby('Tipo')['Sueldo Neto'].apply(lambda x: shapiro(x)[1] if len(x) >= 3 else np.nan)\n",
    "    tipos_validos = normalidad.dropna().index\n",
    "    df_validos = df_year[df_year['Tipo'].isin(tipos_validos)]\n",
    "    \n",
    "    if df_validos.empty:\n",
    "        continue\n",
    "    \n",
    "    # Prueba ANOVA si todas las muestras son normales\n",
    "    if all(normalidad.dropna() > 0.05):\n",
    "        anova_resultados = f_oneway(*[df_validos[df_validos['Tipo'] == tipo]['Sueldo Neto'] for tipo in tipos_validos])\n",
    "        resultados_anova[year] = anova_resultados\n",
    "        if anova_resultados.pvalue < 0.05:\n",
    "            ttest_resultados = {}\n",
    "            for i in range(len(tipos_validos)):\n",
    "                for j in range(i+1, len(tipos_validos)):\n",
    "                    tipo1 = tipos_validos[i]\n",
    "                    tipo2 = tipos_validos[j]\n",
    "                    ttest_resultados[f'{tipo1} vs {tipo2}'] = ttest_ind(df_validos[df_validos['Tipo'] == tipo1]['Sueldo Neto'],\n",
    "                                                                        df_validos[df_validos['Tipo'] == tipo2]['Sueldo Neto'])\n",
    "            print(f\"Resultados de t-test para {year}:\\n\", ttest_resultados)\n",
    "    else:\n",
    "        kruskal_resultados = kruskal(*[df_validos[df_validos['Tipo'] == tipo]['Sueldo Neto'] for tipo in tipos_validos])\n",
    "        resultados_kruskal[year] = kruskal_resultados\n",
    "        if kruskal_resultados.pvalue < 0.05:\n",
    "            tukey_resultados = pairwise_tukeyhsd(df_validos['Sueldo Neto'], df_validos['Tipo'])\n",
    "            print(f\"Resultados de Tukey para {year}:\\n\", tukey_resultados)\n",
    "            \n",
    "            distribuciones[year] = {}\n",
    "            for tipo in tipos_validos:\n",
    "                data = df_validos[df_validos['Tipo'] == tipo]['Sueldo Neto']\n",
    "                distribuciones[year][tipo] = fit_distributions(data)\n",
    "                print(f\"Distribuciones ajustadas para {year}, tipo {tipo}:\\n\", distribuciones[year][tipo])\n",
    "\n",
    "print(\"Resultados de ANOVA:\\n\", resultados_anova)\n",
    "print(\"Resultados de Kruskal-Wallis:\\n\", resultados_kruskal)\n",
    "print(\"Distribuciones ajustadas:\\n\", distribuciones)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5ba7f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecac5cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ea44a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa083ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import shapiro, f_oneway, ttest_ind, kruskal, kstest, norm, lognorm, expon, weibull_min, gamma, f\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Supongamos que el DataFrame df ya está cargado\n",
    "# df = pd.read_csv('csv/typed_itam.csv')\n",
    "# df['Fecha'] = pd.to_datetime(df['Fecha'])\n",
    "\n",
    "# Crear columna de año\n",
    "df['Año'] = df['Fecha'].dt.year\n",
    "\n",
    "# Función para ajustar distribuciones y realizar KS test\n",
    "def fit_and_test_distributions(data):\n",
    "    dist_names = ['norm', 'lognorm', 'expon', 'weibull_min', 'gamma', 'f']\n",
    "    dist_results = {}\n",
    "    for dist_name in dist_names:\n",
    "        dist = getattr(__import__('scipy.stats', fromlist=[dist_name]), dist_name)\n",
    "        params = dist.fit(data)\n",
    "        ks_stat, ks_pvalue = kstest(data, dist_name, args=params)\n",
    "        dist_results[dist_name] = {'params': params, 'ks_pvalue': ks_pvalue}\n",
    "    return dist_results\n",
    "\n",
    "# Pruebas ANOVA y Kruskal-Wallis por año\n",
    "resultados_anova = {}\n",
    "resultados_kruskal = {}\n",
    "distribuciones = {}\n",
    "\n",
    "for year in df['Año'].unique():\n",
    "    df_year = df[df['Año'] == year]\n",
    "    \n",
    "    if df_year.empty:\n",
    "        continue\n",
    "    \n",
    "    normalidad = df_year.groupby('Tipo')['Sueldo Neto'].apply(lambda x: shapiro(x)[1] if len(x) >= 3 else np.nan)\n",
    "    tipos_validos = normalidad.dropna().index\n",
    "    df_validos = df_year[df_year['Tipo'].isin(tipos_validos)]\n",
    "    \n",
    "    if df_validos.empty:\n",
    "        continue\n",
    "    \n",
    "    # Prueba ANOVA si todas las muestras son normales\n",
    "    if all(normalidad.dropna() > 0.05):\n",
    "        anova_resultados = f_oneway(*[df_validos[df_validos['Tipo'] == tipo]['Sueldo Neto'] for tipo in tipos_validos])\n",
    "        resultados_anova[year] = anova_resultados\n",
    "        if anova_resultados.pvalue < 0.05:\n",
    "            ttest_resultados = {}\n",
    "            for i in range(len(tipos_validos)):\n",
    "                for j in range(i+1, len(tipos_validos)):\n",
    "                    tipo1 = tipos_validos[i]\n",
    "                    tipo2 = tipos_validos[j]\n",
    "                    ttest_resultados[f'{tipo1} vs {tipo2}'] = ttest_ind(df_validos[df_validos['Tipo'] == tipo1]['Sueldo Neto'],\n",
    "                                                                        df_validos[df_validos['Tipo'] == tipo2]['Sueldo Neto'])\n",
    "            print(f\"Resultados de t-test para {year}:\\n\", ttest_resultados)\n",
    "    else:\n",
    "        kruskal_resultados = kruskal(*[df_validos[df_validos['Tipo'] == tipo]['Sueldo Neto'] for tipo in tipos_validos])\n",
    "        resultados_kruskal[year] = kruskal_resultados\n",
    "        if kruskal_resultados.pvalue < 0.05:\n",
    "            tukey_resultados = pairwise_tukeyhsd(df_validos['Sueldo Neto'], df_validos['Tipo'])\n",
    "            print(f\"Resultados de Tukey para {year}:\\n\", tukey_resultados)\n",
    "            \n",
    "            distribuciones[year] = {}\n",
    "            for tipo in tipos_validos:\n",
    "                data = df_validos[df_validos['Tipo'] == tipo]['Sueldo Neto']\n",
    "                dist_results = fit_and_test_distributions(data)\n",
    "                distribuciones[year][tipo] = dist_results\n",
    "                \n",
    "                # Resaltar distribuciones que cumplen con el criterio (p-valor alto)\n",
    "                for dist_name, results in dist_results.items():\n",
    "                    if results['ks_pvalue'] > 0.05:\n",
    "                        print(f\"Para el año {year}, el tipo {tipo} sigue una distribución {dist_name} con p-valor de {results['ks_pvalue']:.4f}\")\n",
    "\n",
    "print(\"Resultados de ANOVA:\\n\", resultados_anova)\n",
    "print(\"Resultados de Kruskal-Wallis:\\n\", resultados_kruskal)\n",
    "print(\"Distribuciones ajustadas:\\n\", distribuciones)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010a795d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81f36c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e2188b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856d511e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import shapiro, f_oneway, ttest_ind, kruskal, kstest, norm, lognorm, expon, weibull_min, gamma, f\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Supongamos que el DataFrame df ya está cargado\n",
    "# df = pd.read_csv('csv/typed_itam.csv')\n",
    "# df['Fecha'] = pd.to_datetime(df['Fecha'])\n",
    "\n",
    "# Crear columna de año\n",
    "df['Año'] = df['Fecha'].dt.year\n",
    "\n",
    "# Función para ajustar distribuciones y realizar KS test\n",
    "def fit_and_test_distributions(data):\n",
    "    dist_names = ['norm', 'lognorm', 'expon', 'weibull_min', 'gamma', 'f']\n",
    "    dist_results = {}\n",
    "    for dist_name in dist_names:\n",
    "        dist = getattr(__import__('scipy.stats', fromlist=[dist_name]), dist_name)\n",
    "        params = dist.fit(data)\n",
    "        ks_stat, ks_pvalue = kstest(data, dist_name, args=params)\n",
    "        dist_results[dist_name] = {'params': params, 'ks_pvalue': ks_pvalue}\n",
    "    return dist_results\n",
    "\n",
    "# Pruebas ANOVA y Kruskal-Wallis por año\n",
    "resultados_anova = {}\n",
    "resultados_kruskal = {}\n",
    "distribuciones = {}\n",
    "\n",
    "for year in df['Año'].unique():\n",
    "    df_year = df[df['Año'] == year]\n",
    "    \n",
    "    if df_year.empty:\n",
    "        continue\n",
    "    \n",
    "    normalidad = df_year.groupby('Tipo')['Sueldo Neto'].apply(lambda x: shapiro(x)[1] if len(x) >= 3 else np.nan)\n",
    "    tipos_validos = normalidad.dropna().index\n",
    "    df_validos = df_year[df_year['Tipo'].isin(tipos_validos)]\n",
    "    \n",
    "    if df_validos.empty:\n",
    "        continue\n",
    "    \n",
    "    # Prueba ANOVA si todas las muestras son normales\n",
    "    if all(normalidad.dropna() > 0.05):\n",
    "        anova_resultados = f_oneway(*[df_validos[df_validos['Tipo'] == tipo]['Sueldo Neto'] for tipo in tipos_validos])\n",
    "        resultados_anova[year] = anova_resultados\n",
    "        if anova_resultados.pvalue < 0.05:\n",
    "            ttest_resultados = {}\n",
    "            for i in range(len(tipos_validos)):\n",
    "                for j in range(i+1, len(tipos_validos)):\n",
    "                    tipo1 = tipos_validos[i]\n",
    "                    tipo2 = tipos_validos[j]\n",
    "                    ttest_resultados[f'{tipo1} vs {tipo2}'] = ttest_ind(df_validos[df_validos['Tipo'] == tipo1]['Sueldo Neto'],\n",
    "                                                                        df_validos[df_validos['Tipo'] == tipo2]['Sueldo Neto'])\n",
    "            print(f\"Resultados de t-test para {year}:\\n\", ttest_resultados)\n",
    "    else:\n",
    "        kruskal_resultados = kruskal(*[df_validos[df_validos['Tipo'] == tipo]['Sueldo Neto'] for tipo in tipos_validos])\n",
    "        resultados_kruskal[year] = kruskal_resultados\n",
    "        if kruskal_resultados.pvalue < 0.05:\n",
    "            tukey_resultados = pairwise_tukeyhsd(df_validos['Sueldo Neto'], df_validos['Tipo'])\n",
    "            print(f\"Resultados de Tukey para {year}:\\n\", tukey_resultados)\n",
    "            \n",
    "            distribuciones[year] = {}\n",
    "            for tipo in tipos_validos:\n",
    "                data = df_validos[df_validos['Tipo'] == tipo]['Sueldo Neto']\n",
    "                dist_results = fit_and_test_distributions(data)\n",
    "                # Filtrar y mostrar solo distribuciones con p-valor > 0.05\n",
    "                filtered_dist_results = {dist: res for dist, res in dist_results.items() if res['ks_pvalue'] > 0.05}\n",
    "                if filtered_dist_results:\n",
    "                    distribuciones[year][tipo] = filtered_dist_results\n",
    "                    print(f\"Para el año {year}, el tipo {tipo} sigue las siguientes distribuciones:\\n\", filtered_dist_results)\n",
    "\n",
    "print(\"Resultados de ANOVA:\\n\", resultados_anova)\n",
    "print(\"Resultados de Kruskal-Wallis:\\n\", resultados_kruskal)\n",
    "print(\"Distribuciones ajustadas (con p-valor > 0.05):\\n\", distribuciones)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a678778d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb764dab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1e150c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7986a684",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32a8d4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51fc404",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb41768b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fa4ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Supongamos que el DataFrame df ya está cargado\n",
    "# df = pd.read_csv('csv/typed_itam.csv')\n",
    "# df['Fecha'] = pd.to_datetime(df['Fecha'])\n",
    "\n",
    "# Crear columna de año\n",
    "df['Año'] = df['Fecha'].dt.year\n",
    "\n",
    "def pareto_analysis(df, column, threshold=0.8):\n",
    "    df = df.sort_values(by=column, ascending=False)\n",
    "    df['Cumulative Sum'] = df[column].cumsum()\n",
    "    df['Cumulative Percentage'] = df['Cumulative Sum'] / df[column].sum()\n",
    "    pareto_df = df[df['Cumulative Percentage'] <= threshold]\n",
    "    return pareto_df\n",
    "\n",
    "# Análisis del principio de Pareto para el sueldo neto y cantidad de empleados por dependencia y por año\n",
    "pareto_results_sueldo = {}\n",
    "pareto_results_empleados = {}\n",
    "\n",
    "for year in df['Año'].unique():\n",
    "    df_year = df[df['Año'] == year]\n",
    "    \n",
    "    # Sueldo neto por dependencia\n",
    "    sueldo_por_dependencia = df_year.groupby('dependencia')['Sueldo Neto'].sum().reset_index()\n",
    "    pareto_sueldo = pareto_analysis(sueldo_por_dependencia, 'Sueldo Neto')\n",
    "    pareto_results_sueldo[year] = pareto_sueldo\n",
    "    \n",
    "    # Cantidad de empleados por dependencia\n",
    "    empleados_por_dependencia = df_year.groupby('dependencia')['Nombre'].nunique().reset_index()\n",
    "    empleados_por_dependencia.rename(columns={'Nombre': 'Cantidad Empleados'}, inplace=True)\n",
    "    pareto_empleados = pareto_analysis(empleados_por_dependencia, 'Cantidad Empleados')\n",
    "    pareto_results_empleados[year] = pareto_empleados\n",
    "\n",
    "    # Graficar resultados para el sueldo neto\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(pareto_sueldo['dependencia'], pareto_sueldo['Sueldo Neto'])\n",
    "    plt.title(f'Dependencias que concentran el 80% del Sueldo Neto en {year}')\n",
    "    plt.xlabel('Dependencia')\n",
    "    plt.ylabel('Sueldo Neto')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'img/pareto_sueldo_{year}.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Graficar resultados para la cantidad de empleados\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(pareto_empleados['dependencia'], pareto_empleados['Cantidad Empleados'])\n",
    "    plt.title(f'Dependencias que concentran el 80% de los Empleados en {year}')\n",
    "    plt.xlabel('Dependencia')\n",
    "    plt.ylabel('Cantidad de Empleados')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'img/pareto_empleados_{year}.png')\n",
    "    plt.close()\n",
    "\n",
    "print(\"Resultados del análisis de Pareto para el sueldo neto:\\n\", pareto_results_sueldo)\n",
    "print(\"Resultados del análisis de Pareto para la cantidad de empleados:\\n\", pareto_results_empleados)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6504614",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d16e90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e154e197",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9eecda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Supongamos que el DataFrame df ya está cargado\n",
    "# df = pd.read_csv('csv/typed_itam.csv')\n",
    "# df['Fecha'] = pd.to_datetime(df['Fecha'])\n",
    "\n",
    "# Crear columna de año\n",
    "df['Año'] = df['Fecha'].dt.year\n",
    "\n",
    "# Función para calcular cuartiles y deciles\n",
    "def calculate_quantiles(df, column, quantiles):\n",
    "    return df[column].quantile(quantiles)\n",
    "\n",
    "# Cuartiles y Deciles para el sueldo neto por año\n",
    "cuartiles_results = {}\n",
    "deciles_results = {}\n",
    "\n",
    "for year in df['Año'].unique():\n",
    "    df_year = df[df['Año'] == year]\n",
    "    cuartiles = calculate_quantiles(df_year, 'Sueldo Neto', [0.25, 0.5, 0.75])\n",
    "    deciles = calculate_quantiles(df_year, 'Sueldo Neto', [i / 10 for i in range(1, 10)])\n",
    "    cuartiles_results[year] = cuartiles\n",
    "    deciles_results[year] = deciles\n",
    "\n",
    "    # Graficar cuartiles\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.boxplot(x='Sueldo Neto', data=df_year, showfliers=False)\n",
    "    plt.title(f'Cuartiles del Sueldo Neto en {year}')\n",
    "    plt.xlabel('Sueldo Neto')\n",
    "    plt.savefig(f'img/cuartiles_sueldo_{year}.png')\n",
    "    plt.close()\n",
    "\n",
    "print(\"Resultados de Cuartiles:\\n\", cuartiles_results)\n",
    "print(\"Resultados de Deciles:\\n\", deciles_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43727201",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Función para calcular la curva de Lorenz y el coeficiente de Gini\n",
    "def lorenz_curve(data):\n",
    "    data = np.sort(data)\n",
    "    data_sum = data.sum()\n",
    "    lorenz = np.cumsum(data) / data_sum\n",
    "    lorenz = np.insert(lorenz, 0, 0)\n",
    "    xaxis = np.linspace(0.0, 1.0, len(lorenz))\n",
    "    gini_index = (1 - 2 * np.trapz(lorenz, xaxis))\n",
    "    return xaxis, lorenz, gini_index\n",
    "\n",
    "# Curva de Lorenz y Coeficiente de Gini por año\n",
    "lorenz_results = {}\n",
    "gini_results = {}\n",
    "\n",
    "for year in df['Año'].unique():\n",
    "    df_year = df[df['Año'] == year]\n",
    "    xaxis, lorenz, gini_index = lorenz_curve(df_year['Sueldo Neto'])\n",
    "    lorenz_results[year] = (xaxis, lorenz)\n",
    "    gini_results[year] = gini_index\n",
    "\n",
    "    # Graficar curva de Lorenz\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(xaxis, lorenz, label='Curva de Lorenz')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='black', label='Igualdad Perfecta')\n",
    "    plt.title(f'Curva de Lorenz del Sueldo Neto en {year}')\n",
    "    plt.xlabel('Porcentaje Acumulado de Empleados')\n",
    "    plt.ylabel('Porcentaje Acumulado de Sueldo Neto')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'img/lorenz_sueldo_{year}.png')\n",
    "    plt.close()\n",
    "\n",
    "print(\"Resultados de Gini:\\n\", gini_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e05c1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráficos de densidad de kernel por año\n",
    "for year in df['Año'].unique():\n",
    "    df_year = df[df['Año'] == year]\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.kdeplot(df_year['Sueldo Neto'], shade=True)\n",
    "    plt.title(f'Densidad de Kernel del Sueldo Neto en {year}')\n",
    "    plt.xlabel('Sueldo Neto')\n",
    "    plt.ylabel('Densidad')\n",
    "    plt.savefig(f'img/densidad_sueldo_{year}.png')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0160af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramas con escala logarítmica por año\n",
    "for year in df['Año'].unique():\n",
    "    df_year = df[df['Año'] == year]\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.hist(df_year['Sueldo Neto'], bins=50, log=True)\n",
    "    plt.title(f'Histograma del Sueldo Neto en {year} (Escala Logarítmica)')\n",
    "    plt.xlabel('Sueldo Neto')\n",
    "    plt.ylabel('Frecuencia (Escala Logarítmica)')\n",
    "    plt.savefig(f'img/histograma_sueldo_log_{year}.png')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe14746",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36a7962",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e93706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb942a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Supongamos que el DataFrame df ya está cargado\n",
    "# df = pd.read_csv('csv/typed_itam.csv')\n",
    "# df['Fecha'] = pd.to_datetime(df['Fecha'])\n",
    "\n",
    "# Función para calcular cuartiles y deciles\n",
    "def calculate_quantiles(df, column, quantiles):\n",
    "    return df[column].quantile(quantiles)\n",
    "\n",
    "# Cuartiles y Deciles para el sueldo neto total\n",
    "cuartiles = calculate_quantiles(df, 'Sueldo Neto', [0.25, 0.5, 0.75])\n",
    "deciles = calculate_quantiles(df, 'Sueldo Neto', [i / 10 for i in range(1, 10)])\n",
    "\n",
    "# Graficar cuartiles\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.boxplot(x='Sueldo Neto', data=df, showfliers=False)\n",
    "plt.title('Cuartiles del Sueldo Neto Total')\n",
    "plt.xlabel('Sueldo Neto')\n",
    "plt.savefig('img/cuartiles_sueldo_total.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"Cuartiles del Sueldo Neto Total:\\n\", cuartiles)\n",
    "print(\"Deciles del Sueldo Neto Total:\\n\", deciles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f7167b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Función para calcular la curva de Lorenz y el coeficiente de Gini\n",
    "def lorenz_curve(data):\n",
    "    data = np.sort(data)\n",
    "    data_sum = data.sum()\n",
    "    lorenz = np.cumsum(data) / data_sum\n",
    "    lorenz = np.insert(lorenz, 0, 0)\n",
    "    xaxis = np.linspace(0.0, 1.0, len(lorenz))\n",
    "    gini_index = (1 - 2 * np.trapz(lorenz, xaxis))\n",
    "    return xaxis, lorenz, gini_index\n",
    "\n",
    "# Curva de Lorenz y Coeficiente de Gini para el sueldo neto total\n",
    "xaxis, lorenz, gini_index = lorenz_curve(df['Sueldo Neto'])\n",
    "\n",
    "# Graficar curva de Lorenz\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(xaxis, lorenz, label='Curva de Lorenz')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='black', label='Igualdad Perfecta')\n",
    "plt.title('Curva de Lorenz del Sueldo Neto Total')\n",
    "plt.xlabel('Porcentaje Acumulado de Empleados')\n",
    "plt.ylabel('Porcentaje Acumulado de Sueldo Neto')\n",
    "plt.legend()\n",
    "plt.savefig('img/lorenz_sueldo_total.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"Coeficiente de Gini del Sueldo Neto Total:\\n\", gini_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d2d7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de densidad de kernel para el sueldo neto total\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.kdeplot(df['Sueldo Neto'], shade=True)\n",
    "plt.title('Densidad de Kernel del Sueldo Neto Total')\n",
    "plt.xlabel('Sueldo Neto')\n",
    "plt.ylabel('Densidad')\n",
    "plt.savefig('img/densidad_sueldo_total.png')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91e6723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograma con escala logarítmica para el sueldo neto total\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(df['Sueldo Neto'], bins=50, log=True)\n",
    "plt.title('Histograma del Sueldo Neto Total (Escala Logarítmica)')\n",
    "plt.xlabel('Sueldo Neto')\n",
    "plt.ylabel('Frecuencia (Escala Logarítmica)')\n",
    "plt.savefig('img/histograma_sueldo_log_total.png')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c80715",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcd53d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e5785a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4de6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import shapiro, f_oneway, ttest_ind, kruskal, kstest, norm, lognorm, expon, weibull_min, gamma, f\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Supongamos que el DataFrame df ya está cargado\n",
    "# df = pd.read_csv('csv/typed_itam.csv')\n",
    "# df['Fecha'] = pd.to_datetime(df['Fecha'])\n",
    "\n",
    "# Función para ajustar distribuciones y realizar KS test\n",
    "def fit_and_test_distributions(data):\n",
    "    dist_names = ['norm', 'lognorm', 'expon', 'weibull_min', 'gamma', 'f']\n",
    "    dist_results = {}\n",
    "    for dist_name in dist_names:\n",
    "        dist = getattr(__import__('scipy.stats', fromlist=[dist_name]), dist_name)\n",
    "        params = dist.fit(data)\n",
    "        ks_stat, ks_pvalue = kstest(data, dist_name, args=params)\n",
    "        dist_results[dist_name] = {'params': params, 'ks_pvalue': ks_pvalue}\n",
    "    return dist_results\n",
    "\n",
    "# Agrupación por tipo de dependencia\n",
    "resultados_anova_tipo = {}\n",
    "resultados_kruskal_tipo = {}\n",
    "distribuciones_tipo = {}\n",
    "\n",
    "normalidad_tipo = df.groupby('Tipo')['Sueldo Neto'].apply(lambda x: shapiro(x)[1] if len(x) >= 3 else np.nan)\n",
    "tipos_validos = normalidad_tipo.dropna().index\n",
    "df_validos_tipo = df[df['Tipo'].isin(tipos_validos)]\n",
    "\n",
    "# Prueba ANOVA si todas las muestras son normales\n",
    "if all(normalidad_tipo.dropna() > 0.05):\n",
    "    anova_resultados = f_oneway(*[df_validos_tipo[df_validos_tipo['Tipo'] == tipo]['Sueldo Neto'] for tipo in tipos_validos])\n",
    "    resultados_anova_tipo = anova_resultados\n",
    "    if anova_resultados.pvalue < 0.05:\n",
    "        ttest_resultados = {}\n",
    "        for i in range(len(tipos_validos)):\n",
    "            for j in range(i+1, len(tipos_validos)):\n",
    "                tipo1 = tipos_validos[i]\n",
    "                tipo2 = tipos_validos[j]\n",
    "                ttest_resultados[f'{tipo1} vs {tipo2}'] = ttest_ind(df_validos_tipo[df_validos_tipo['Tipo'] == tipo1]['Sueldo Neto'],\n",
    "                                                                    df_validos_tipo[df_validos_tipo['Tipo'] == tipo2]['Sueldo Neto'])\n",
    "        print(f\"Resultados de t-test por Tipo:\\n\", ttest_resultados)\n",
    "else:\n",
    "    kruskal_resultados = kruskal(*[df_validos_tipo[df_validos_tipo['Tipo'] == tipo]['Sueldo Neto'] for tipo in tipos_validos])\n",
    "    resultados_kruskal_tipo = kruskal_resultados\n",
    "    if kruskal_resultados.pvalue < 0.05:\n",
    "        tukey_resultados = pairwise_tukeyhsd(df_validos_tipo['Sueldo Neto'], df_validos_tipo['Tipo'])\n",
    "        print(f\"Resultados de Tukey por Tipo:\\n\", tukey_resultados)\n",
    "        \n",
    "        distribuciones_tipo = {}\n",
    "        for tipo in tipos_validos:\n",
    "            data = df_validos_tipo[df_validos_tipo['Tipo'] == tipo]['Sueldo Neto']\n",
    "            dist_results = fit_and_test_distributions(data)\n",
    "            # Filtrar y mostrar solo distribuciones con p-valor > 0.05\n",
    "            filtered_dist_results = {dist: res for dist, res in dist_results.items() if res['ks_pvalue'] > 0.05}\n",
    "            if filtered_dist_results:\n",
    "                distribuciones_tipo[tipo] = filtered_dist_results\n",
    "                print(f\"Para el tipo {tipo} sigue las siguientes distribuciones:\\n\", filtered_dist_results)\n",
    "\n",
    "print(\"Resultados de ANOVA por Tipo:\\n\", resultados_anova_tipo)\n",
    "print(\"Resultados de Kruskal-Wallis por Tipo:\\n\", resultados_kruskal_tipo)\n",
    "print(\"Distribuciones ajustadas por Tipo (con p-valor > 0.05):\\n\", distribuciones_tipo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf186d6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463a1743",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a835b0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c3bbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupación por dependencia\n",
    "resultados_anova_dep = {}\n",
    "resultados_kruskal_dep = {}\n",
    "distribuciones_dep = {}\n",
    "\n",
    "normalidad_dep = df.groupby('dependencia')['Sueldo Neto'].apply(lambda x: shapiro(x)[1] if len(x) >= 3 else np.nan)\n",
    "deps_validos = normalidad_dep.dropna().index\n",
    "df_validos_dep = df[df['dependencia'].isin(deps_validos)]\n",
    "\n",
    "# Prueba ANOVA si todas las muestras son normales\n",
    "if all(normalidad_dep.dropna() > 0.05):\n",
    "    anova_resultados = f_oneway(*[df_validos_dep[df_validos_dep['dependencia'] == dep]['Sueldo Neto'] for dep in deps_validos])\n",
    "    resultados_anova_dep = anova_resultados\n",
    "    if anova_resultados.pvalue < 0.05:\n",
    "        ttest_resultados = {}\n",
    "        for i in range(len(deps_validos)):\n",
    "            for j in range(i+1, len(deps_validos)):\n",
    "                dep1 = deps_validos[i]\n",
    "                dep2 = deps_validos[j]\n",
    "                ttest_resultados[f'{dep1} vs {dep2}'] = ttest_ind(df_validos_dep[df_validos_dep['dependencia'] == dep1]['Sueldo Neto'],\n",
    "                                                                  df_validos_dep[df_validos_dep['dependencia'] == dep2]['Sueldo Neto'])\n",
    "        print(f\"Resultados de t-test por Dependencia:\\n\", ttest_resultados)\n",
    "else:\n",
    "    kruskal_resultados = kruskal(*[df_validos_dep[df_validos_dep['dependencia'] == dep]['Sueldo Neto'] for dep in deps_validos])\n",
    "    resultados_kruskal_dep = kruskal_resultados\n",
    "    if kruskal_resultados.pvalue < 0.05:\n",
    "        tukey_resultados = pairwise_tukeyhsd(df_validos_dep['Sueldo Neto'], df_validos_dep['dependencia'])\n",
    "        print(f\"Resultados de Tukey por Dependencia:\\n\", tukey_resultados)\n",
    "        \n",
    "        distribuciones_dep = {}\n",
    "        for dep in deps_validos:\n",
    "            data = df_validos_dep[df_validos_dep['dependencia'] == dep]['Sueldo Neto']\n",
    "            dist_results = fit_and_test_distributions(data)\n",
    "            # Filtrar y mostrar solo distribuciones con p-valor > 0.05\n",
    "            filtered_dist_results = {dist: res for dist, res in dist_results.items() if res['ks_pvalue'] > 0.05}\n",
    "            if filtered_dist_results:\n",
    "                distribuciones_dep[dep] = filtered_dist_results\n",
    "                print(f\"Para la dependencia {dep} sigue las siguientes distribuciones:\\n\", filtered_dist_results)\n",
    "\n",
    "print(\"Resultados de ANOVA por Dependencia:\\n\", resultados_anova_dep)\n",
    "print(\"Resultados de Kruskal-Wallis por Dependencia:\\n\", resultados_kruskal_dep)\n",
    "print(\"Distribuciones ajustadas por Dependencia (con p-valor > 0.05):\\n\", distribuciones_dep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec605787",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3856e02c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f91f32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3622a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb7b7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import shapiro, f_oneway, ttest_ind, kruskal, kstest, norm, lognorm, expon, weibull_min, gamma, f\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Supongamos que el DataFrame df ya está cargado\n",
    "# df = pd.read_csv('csv/typed_itam.csv')\n",
    "# df['Fecha'] = pd.to_datetime(df['Fecha'])\n",
    "\n",
    "# Función para ajustar distribuciones y realizar KS test\n",
    "def fit_and_test_distributions(data):\n",
    "    dist_names = ['norm', 'lognorm', 'expon', 'weibull_min', 'gamma', 'f']\n",
    "    dist_results = {}\n",
    "    for dist_name in dist_names:\n",
    "        dist = getattr(__import__('scipy.stats', fromlist=[dist_name]), dist_name)\n",
    "        params = dist.fit(data)\n",
    "        ks_stat, ks_pvalue = kstest(data, dist_name, args=params)\n",
    "        dist_results[dist_name] = {'params': params, 'ks_pvalue': ks_pvalue}\n",
    "    return dist_results\n",
    "\n",
    "def save_results_to_file(filename, content):\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(content)\n",
    "\n",
    "# Agrupación por tipo de dependencia\n",
    "resultados_anova_tipo = {}\n",
    "resultados_kruskal_tipo = {}\n",
    "distribuciones_tipo = {}\n",
    "\n",
    "normalidad_tipo = df.groupby('Tipo')['Sueldo Neto'].apply(lambda x: shapiro(x)[1] if len(x) >= 3 else np.nan)\n",
    "tipos_validos = normalidad_tipo.dropna().index\n",
    "df_validos_tipo = df[df['Tipo'].isin(tipos_validos)]\n",
    "\n",
    "# Prueba ANOVA si todas las muestras son normales\n",
    "if all(normalidad_tipo.dropna() > 0.05):\n",
    "    anova_resultados = f_oneway(*[df_validos_tipo[df_validos_tipo['Tipo'] == tipo]['Sueldo Neto'] for tipo in tipos_validos])\n",
    "    resultados_anova_tipo = anova_resultados\n",
    "    if anova_resultados.pvalue < 0.05:\n",
    "        ttest_resultados = {}\n",
    "        for i in tqdm(range(len(tipos_validos)), desc=\"T-test por Tipo\"):\n",
    "            for j in range(i+1, len(tipos_validos)):\n",
    "                tipo1 = tipos_validos[i]\n",
    "                tipo2 = tipos_validos[j]\n",
    "                ttest_resultados[f'{tipo1} vs {tipo2}'] = ttest_ind(df_validos_tipo[df_validos_tipo['Tipo'] == tipo1]['Sueldo Neto'],\n",
    "                                                                    df_validos_tipo[df_validos_tipo['Tipo'] == tipo2]['Sueldo Neto'])\n",
    "        save_results_to_file('ttest_resultados_tipo.txt', str(ttest_resultados))\n",
    "else:\n",
    "    kruskal_resultados = kruskal(*[df_validos_tipo[df_validos_tipo['Tipo'] == tipo]['Sueldo Neto'] for tipo in tipos_validos])\n",
    "    resultados_kruskal_tipo = kruskal_resultados\n",
    "    if kruskal_resultados.pvalue < 0.05:\n",
    "        tukey_resultados = pairwise_tukeyhsd(df_validos_tipo['Sueldo Neto'], df_validos_tipo['Tipo'])\n",
    "        save_results_to_file('tukey_resultados_tipo.txt', str(tukey_resultados))\n",
    "        \n",
    "        distribuciones_tipo = {}\n",
    "        for tipo in tqdm(tipos_validos, desc=\"Distribuciones por Tipo\"):\n",
    "            data = df_validos_tipo[df_validos_tipo['Tipo'] == tipo]['Sueldo Neto']\n",
    "            dist_results = fit_and_test_distributions(data)\n",
    "            # Filtrar y mostrar solo distribuciones con p-valor > 0.05\n",
    "            filtered_dist_results = {dist: res for dist, res in dist_results.items() if res['ks_pvalue'] > 0.05}\n",
    "            if filtered_dist_results:\n",
    "                distribuciones_tipo[tipo] = filtered_dist_results\n",
    "        save_results_to_file('distribuciones_tipo.txt', str(distribuciones_tipo))\n",
    "\n",
    "save_results_to_file('resultados_anova_tipo.txt', str(resultados_anova_tipo))\n",
    "save_results_to_file('resultados_kruskal_tipo.txt', str(resultados_kruskal_tipo))\n",
    "\n",
    "# Agrupación por dependencia\n",
    "resultados_anova_dep = {}\n",
    "resultados_kruskal_dep = {}\n",
    "distribuciones_dep = {}\n",
    "\n",
    "normalidad_dep = df.groupby('dependencia')['Sueldo Neto'].apply(lambda x: shapiro(x)[1] if len(x) >= 3 else np.nan)\n",
    "deps_validos = normalidad_dep.dropna().index\n",
    "df_validos_dep = df[df['dependencia'].isin(deps_validos)]\n",
    "\n",
    "# Prueba ANOVA si todas las muestras son normales\n",
    "if all(normalidad_dep.dropna() > 0.05):\n",
    "    anova_resultados = f_oneway(*[df_validos_dep[df_validos_dep['dependencia'] == dep]['Sueldo Neto'] for dep in deps_validos])\n",
    "    resultados_anova_dep = anova_resultados\n",
    "    if anova_resultados.pvalue < 0.05:\n",
    "        ttest_resultados = {}\n",
    "        for i in tqdm(range(len(deps_validos)), desc=\"T-test por Dependencia\"):\n",
    "            for j in range(i+1, len(deps_validos)):\n",
    "                dep1 = deps_validos[i]\n",
    "                dep2 = deps_validos[j]\n",
    "                ttest_resultados[f'{dep1} vs {dep2}'] = ttest_ind(df_validos_dep[df_validos_dep['dependencia'] == dep1]['Sueldo Neto'],\n",
    "                                                                  df_validos_dep[df_validos_dep['dependencia'] == dep2]['Sueldo Neto'])\n",
    "        save_results_to_file('ttest_resultados_dep.txt', str(ttest_resultados))\n",
    "else:\n",
    "    kruskal_resultados = kruskal(*[df_validos_dep[df_validos_dep['dependencia'] == dep]['Sueldo Neto'] for dep in deps_validos])\n",
    "    resultados_kruskal_dep = kruskal_resultados\n",
    "    if kruskal_resultados.pvalue < 0.05:\n",
    "        tukey_resultados = pairwise_tukeyhsd(df_validos_dep['Sueldo Neto'], df_validos_dep['dependencia'])\n",
    "        save_results_to_file('tukey_resultados_dep.txt', str(tukey_resultados))\n",
    "        \n",
    "        distribuciones_dep = {}\n",
    "        for dep in tqdm(deps_validos, desc=\"Distribuciones por Dependencia\"):\n",
    "            data = df_validos_dep[df_validos_dep['dependencia'] == dep]['Sueldo Neto']\n",
    "            dist_results = fit_and_test_distributions(data)\n",
    "            # Filtrar y mostrar solo distribuciones con p-valor > 0.05\n",
    "            filtered_dist_results = {dist: res for dist, res in dist_results.items() if res['ks_pvalue'] > 0.05}\n",
    "            if filtered_dist_results:\n",
    "                distribuciones_dep[dep] = filtered_dist_results\n",
    "        save_results_to_file('distribuciones_dep.txt', str(distribuciones_dep))\n",
    "\n",
    "save_results_to_file('resultados_anova_dep.txt', str(resultados_anova_dep))\n",
    "save_results_to_file('resultados_kruskal_dep.txt', str(resultados_kruskal_dep))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bb792f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d9ca5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e4c749",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fd64b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import shapiro, f_oneway, ttest_ind, kruskal, kstest, norm, lognorm, expon, weibull_min, gamma, f\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# Supongamos que el DataFrame df ya está cargado\n",
    "# df = pd.read_csv('csv/typed_itam.csv')\n",
    "# df['Fecha'] = pd.to_datetime(df['Fecha'])\n",
    "\n",
    "# Limpiar los datos de sueldos netos\n",
    "df = df.replace([np.inf, -np.inf], np.nan).dropna(subset=['Sueldo Neto'])\n",
    "df = df[df['Sueldo Neto'] > 0]\n",
    "\n",
    "# Función para ajustar distribuciones y realizar KS test\n",
    "def fit_and_test_distributions(data):\n",
    "    dist_names = ['norm', 'lognorm', 'expon', 'weibull_min', 'gamma', 'f']\n",
    "    dist_results = {}\n",
    "    for dist_name in dist_names:\n",
    "        dist = getattr(__import__('scipy.stats', fromlist=[dist_name]), dist_name)\n",
    "        params = dist.fit(data)\n",
    "        ks_stat, ks_pvalue = kstest(data, dist_name, args=params)\n",
    "        dist_results[dist_name] = {'params': params, 'ks_pvalue': ks_pvalue}\n",
    "    return dist_results\n",
    "\n",
    "def save_results_to_file(filename, content):\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(content)\n",
    "\n",
    "# Agrupación por tipo de dependencia\n",
    "resultados_anova_tipo = {}\n",
    "resultados_kruskal_tipo = {}\n",
    "distribuciones_tipo = {}\n",
    "\n",
    "normalidad_tipo = df.groupby('Tipo')['Sueldo Neto'].apply(lambda x: shapiro(x)[1] if len(x) >= 3 else np.nan)\n",
    "tipos_validos = normalidad_tipo.dropna().index\n",
    "df_validos_tipo = df[df['Tipo'].isin(tipos_validos)]\n",
    "\n",
    "# Prueba ANOVA si todas las muestras son normales\n",
    "if all(normalidad_tipo.dropna() > 0.05):\n",
    "    anova_resultados = f_oneway(*[df_validos_tipo[df_validos_tipo['Tipo'] == tipo]['Sueldo Neto'] for tipo in tipos_validos])\n",
    "    resultados_anova_tipo = anova_resultados\n",
    "    if anova_resultados.pvalue < 0.05:\n",
    "        ttest_resultados = {}\n",
    "        for i in tqdm(range(len(tipos_validos)), desc=\"T-test por Tipo\"):\n",
    "            for j in range(i+1, len(tipos_validos)):\n",
    "                tipo1 = tipos_validos[i]\n",
    "                tipo2 = tipos_validos[j]\n",
    "                ttest_resultados[f'{tipo1} vs {tipo2}'] = ttest_ind(df_validos_tipo[df_validos_tipo['Tipo'] == tipo1]['Sueldo Neto'],\n",
    "                                                                    df_validos_tipo[df_validos_tipo['Tipo'] == tipo2]['Sueldo Neto'])\n",
    "        save_results_to_file('ttest_resultados_tipo.txt', str(ttest_resultados))\n",
    "else:\n",
    "    kruskal_resultados = kruskal(*[df_validos_tipo[df_validos_tipo['Tipo'] == tipo]['Sueldo Neto'] for tipo in tipos_validos])\n",
    "    resultados_kruskal_tipo = kruskal_resultados\n",
    "    if kruskal_resultados.pvalue < 0.05:\n",
    "        tukey_resultados = pairwise_tukeyhsd(df_validos_tipo['Sueldo Neto'], df_validos_tipo['Tipo'])\n",
    "        save_results_to_file('tukey_resultados_tipo.txt', str(tukey_resultados))\n",
    "        \n",
    "        distribuciones_tipo = {}\n",
    "        for tipo in tqdm(tipos_validos, desc=\"Distribuciones por Tipo\"):\n",
    "            data = df_validos_tipo[df_validos_tipo['Tipo'] == tipo]['Sueldo Neto']\n",
    "            dist_results = fit_and_test_distributions(data)\n",
    "            # Filtrar y mostrar solo distribuciones con p-valor > 0.05\n",
    "            filtered_dist_results = {dist: res for dist, res in dist_results.items() if res['ks_pvalue'] > 0.05}\n",
    "            if filtered_dist_results:\n",
    "                distribuciones_tipo[tipo] = filtered_dist_results\n",
    "        save_results_to_file('distribuciones_tipo.txt', str(distribuciones_tipo))\n",
    "\n",
    "save_results_to_file('resultados_anova_tipo.txt', str(resultados_anova_tipo))\n",
    "save_results_to_file('resultados_kruskal_tipo.txt', str(resultados_kruskal_tipo))\n",
    "\n",
    "# Agrupación por dependencia\n",
    "resultados_anova_dep = {}\n",
    "resultados_kruskal_dep = {}\n",
    "distribuciones_dep = {}\n",
    "\n",
    "normalidad_dep = df.groupby('dependencia')['Sueldo Neto'].apply(lambda x: shapiro(x)[1] if len(x) >= 3 else np.nan)\n",
    "deps_validos = normalidad_dep.dropna().index\n",
    "df_validos_dep = df[df['dependencia'].isin(deps_validos)]\n",
    "\n",
    "# Prueba ANOVA si todas las muestras son normales\n",
    "if all(normalidad_dep.dropna() > 0.05):\n",
    "    anova_resultados = f_oneway(*[df_validos_dep[df_validos_dep['dependencia'] == dep]['Sueldo Neto'] for dep in deps_validos])\n",
    "    resultados_anova_dep = anova_resultados\n",
    "    if anova_resultados.pvalue < 0.05:\n",
    "        ttest_resultados = {}\n",
    "        for i in tqdm(range(len(deps_validos)), desc=\"T-test por Dependencia\"):\n",
    "            for j in range(i+1, len(deps_validos)):\n",
    "                dep1 = deps_validos[i]\n",
    "                dep2 = deps_validos[j]\n",
    "                ttest_resultados[f'{dep1} vs {dep2}'] = ttest_ind(df_validos_dep[df_validos_dep['dependencia'] == dep1]['Sueldo Neto'],\n",
    "                                                                  df_validos_dep[df_validos_dep['dependencia'] == dep2]['Sueldo Neto'])\n",
    "        save_results_to_file('ttest_resultados_dep.txt', str(ttest_resultados))\n",
    "else:\n",
    "    kruskal_resultados = kruskal(*[df_validos_dep[df_validos_dep['dependencia'] == dep]['Sueldo Neto'] for dep in deps_validos])\n",
    "    resultados_kruskal_dep = kruskal_resultados\n",
    "    if kruskal_resultados.pvalue < 0.05:\n",
    "        tukey_resultados = pairwise_tukeyhsd(df_validos_dep['Sueldo Neto'], df_validos_dep['dependencia'])\n",
    "        save_results_to_file('tukey_resultados_dep.txt', str(tukey_resultados))\n",
    "        \n",
    "        distribuciones_dep = {}\n",
    "        for dep in tqdm(deps_validos, desc=\"Distribuciones por Dependencia\"):\n",
    "            data = df_validos_dep[df_validos_dep['dependencia'] == dep]['Sueldo Neto']\n",
    "            dist_results = fit_and_test_distributions(data)\n",
    "            # Filtrar y mostrar solo distribuciones con p-valor > 0.05\n",
    "            filtered_dist_results = {dist: res for dist, res in dist_results.items() if res['ks_pvalue'] > 0.05}\n",
    "            if filtered_dist_results:\n",
    "                distribuciones_dep[dep] = filtered_dist_results\n",
    "        save_results_to_file('distribuciones_dep.txt', str(distribuciones_dep))\n",
    "\n",
    "save_results_to_file('resultados_anova_dep.txt', str(resultados_anova_dep))\n",
    "save_results_to_file('resultados_kruskal_dep.txt', str(resultados_kruskal_dep))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84065882",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ffb4a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132cf455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae7ed6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233c4bf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a676ec81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7affde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab2a029",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459de8f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f614cf44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1dcb60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a20112",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0369b3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535fc4a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e410a2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Prueba ANOVA y pruebas adicionales\n",
    "\n",
    "# Verificar normalidad de las muestras por dependencia (solo en Sueldo Neto)\n",
    "normalidad = df.groupby('dependencia')['Sueldo Neto'].apply(lambda x: shapiro(x)[1] if len(x) >= 3 else np.nan)\n",
    "print(\"Resultados de normalidad (p-values):\\n\", normalidad)\n",
    "\n",
    "# Dependencias con datos suficientes para ANOVA o Kruskal-Wallis\n",
    "dependencias_validas = normalidad.dropna().index\n",
    "\n",
    "# Filtrar el DataFrame para las dependencias válidas\n",
    "df_validas = df[df['dependencia'].isin(dependencias_validas)]\n",
    "\n",
    "# Prueba ANOVA si todas las muestras son normales\n",
    "anova_resultados = f_oneway(*[df_validas[df_validas['dependencia'] == dep]['Sueldo Neto'] for dep in dependencias_validas])\n",
    "print('Resultados de ANOVA:', anova_resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb27089f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if anova_resultados.pvalue < 0.05:\n",
    "    print(\"Existen diferencias significativas entre las dependencias. Proceder con pruebas adicionales.\")\n",
    "    ttest_resultados = {}\n",
    "    for i in range(len(dependencias_validas)):\n",
    "        print(f\"i: {i}\")\n",
    "        for j in range(i+1, len(dependencias_validas)):\n",
    "            print(f\"j: {j}\")\n",
    "            dep1 = dependencias_validas[i]\n",
    "            dep2 = dependencias_validas[j]\n",
    "            ttest_resultados[f'{dep1} vs {dep2}'] = ttest_ind(df_validas[df_validas['dependencia'] == dep1]['Sueldo Neto'],\n",
    "                                                               df_validas[df_validas['dependencia'] == dep2]['Sueldo Neto'])\n",
    "        print(ttest_resultados)\n",
    "    print(ttest_resultados)\n",
    "else:\n",
    "    print(\"No existen diferencias significativas entre las dependencias según ANOVA.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a78c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prueba Kruskal-Wallis si alguna muestra no es normal\n",
    "kruskal_resultados = kruskal(*[df_validas[df_validas['dependencia'] == dep]['Sueldo Neto'] for dep in dependencias_validas])\n",
    "print('Resultados de Kruskal-Wallis:', kruskal_resultados)\n",
    "\n",
    "if kruskal_resultados.pvalue < 0.05:\n",
    "    print(\"Existen diferencias significativas entre las dependencias. Proceder con prueba de Tukey.\")\n",
    "    tukey_resultados = pairwise_tukeyhsd(df_validas['Sueldo Neto'], df_validas['dependencia'])\n",
    "    print(tukey_resultados)\n",
    "else:\n",
    "    print(\"No existen diferencias significativas entre las dependencias según Kruskal-Wallis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cdae4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a1f162",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702555f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4637f8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Supongamos que el DataFrame df ya está cargado\n",
    "# df = pd.read_csv('csv/typed_itam.csv')\n",
    "# df['Fecha'] = pd.to_datetime(df['Fecha'])\n",
    "\n",
    "# Ordenar el DataFrame por fecha\n",
    "df = df.sort_values('Fecha')\n",
    "\n",
    "# Obtener las fechas únicas ordenadas\n",
    "fechas = df['Fecha'].drop_duplicates().sort_values()\n",
    "\n",
    "# Inicializar variables\n",
    "dependencias_iniciales = set(df[df['Fecha'] == fechas.iloc[0]]['dependencia'].unique())\n",
    "dependencias_previas = dependencias_iniciales\n",
    "\n",
    "# Diccionarios para almacenar dependencias nuevas y dependencias que dejaron de existir\n",
    "dependencias_nuevas = {}\n",
    "dependencias_bajas = {}\n",
    "\n",
    "# Iterar sobre las fechas después del primer mes\n",
    "for fecha in fechas[1:]:\n",
    "    dependencias_actuales = set(df[df['Fecha'] == fecha]['dependencia'].unique())\n",
    "    \n",
    "    # Identificar nuevas dependencias\n",
    "    nuevas = dependencias_actuales - dependencias_previas\n",
    "    if nuevas:\n",
    "        dependencias_nuevas[fecha.strftime('%Y-%m')] = list(nuevas)\n",
    "    \n",
    "    # Identificar dependencias que dejaron de existir\n",
    "    bajas = dependencias_previas - dependencias_actuales\n",
    "    if bajas:\n",
    "        dependencias_bajas[fecha.strftime('%Y-%m')] = list(bajas)\n",
    "    \n",
    "    # Actualizar el conjunto de dependencias previas\n",
    "    dependencias_previas = dependencias_actuales\n",
    "\n",
    "# Filtrar dependencias que realmente dejaron de existir (considerando la última fecha)\n",
    "dependencias_finales = set(df[df['Fecha'] == fechas.max()]['dependencia'].unique())\n",
    "dependencias_bajas_reales = {k: [dep for dep in v if dep not in dependencias_finales] for k, v in dependencias_bajas.items()}\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(\"Dependencias nuevas:\\n\", dependencias_nuevas)\n",
    "print(\"Dependencias que dejaron de existir:\\n\", dependencias_bajas_reales)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55c9619",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Supongamos que el DataFrame df ya está cargado\n",
    "# df = pd.read_csv('csv/typed_itam.csv')\n",
    "# df['Fecha'] = pd.to_datetime(df['Fecha'])\n",
    "\n",
    "# Ordenar el DataFrame por fecha\n",
    "df = df.sort_values('Fecha')\n",
    "\n",
    "# Obtener las fechas únicas ordenadas\n",
    "fechas = df['Fecha'].drop_duplicates().sort_values()\n",
    "\n",
    "# Inicializar variables\n",
    "dependencias_iniciales = set(df[df['Fecha'] == fechas.iloc[0]]['dependencia'].unique())\n",
    "dependencias_previas = dependencias_iniciales\n",
    "\n",
    "# Diccionarios para almacenar dependencias nuevas, bajas y nuevas luego dadas de baja\n",
    "dependencias_nuevas = {}\n",
    "dependencias_bajas = {}\n",
    "dependencias_nuevas_bajas = {}\n",
    "\n",
    "# Conjunto para almacenar todas las dependencias nuevas\n",
    "todas_dependencias_nuevas = set()\n",
    "\n",
    "# Iterar sobre las fechas después del primer mes\n",
    "for fecha in fechas[1:]:\n",
    "    dependencias_actuales = set(df[df['Fecha'] == fecha]['dependencia'].unique())\n",
    "    \n",
    "    # Identificar nuevas dependencias\n",
    "    nuevas = dependencias_actuales - dependencias_previas\n",
    "    if nuevas:\n",
    "        dependencias_nuevas[fecha.strftime('%Y-%m')] = list(nuevas)\n",
    "        todas_dependencias_nuevas.update(nuevas)\n",
    "    \n",
    "    # Identificar dependencias que dejaron de existir\n",
    "    bajas = dependencias_previas - dependencias_actuales\n",
    "    if bajas:\n",
    "        dependencias_bajas[fecha.strftime('%Y-%m')] = list(bajas)\n",
    "    \n",
    "    # Actualizar el conjunto de dependencias previas\n",
    "    dependencias_previas = dependencias_actuales\n",
    "\n",
    "# Filtrar dependencias que realmente dejaron de existir (considerando la última fecha)\n",
    "dependencias_finales = set(df[df['Fecha'] == fechas.max()]['dependencia'].unique())\n",
    "dependencias_bajas_reales = {k: [dep for dep in v if dep not in dependencias_finales] for k, v in dependencias_bajas.items()}\n",
    "\n",
    "# Identificar dependencias nuevas que luego se dieron de baja\n",
    "for fecha, bajas in dependencias_bajas_reales.items():\n",
    "    nuevas_bajas = [dep for dep in bajas if dep in todas_dependencias_nuevas]\n",
    "    if nuevas_bajas:\n",
    "        dependencias_nuevas_bajas[fecha] = nuevas_bajas\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(\"Dependencias nuevas:\\n\", dependencias_nuevas)\n",
    "print(\"Dependencias que dejaron de existir:\\n\", dependencias_bajas_reales)\n",
    "print(\"Dependencias nuevas que luego se dieron de baja:\\n\", dependencias_nuevas_bajas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ca01d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecedbf8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c563c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17b672e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Supongamos que el DataFrame df ya está cargado\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# df = pd.read_csv('csv/typed_itam.csv')\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# df['Fecha'] = pd.to_datetime(df['Fecha'])\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Crear columna de año\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAño\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFecha\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39myear\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Gráficos de boxplot por dependencia\u001b[39;00m\n\u001b[0;32m     13\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Supongamos que el DataFrame df ya está cargado\n",
    "# df = pd.read_csv('csv/typed_itam.csv')\n",
    "# df['Fecha'] = pd.to_datetime(df['Fecha'])\n",
    "\n",
    "# Crear columna de año\n",
    "df['Año'] = df['Fecha'].dt.year\n",
    "\n",
    "# Gráficos de boxplot por dependencia\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.boxplot(x='dependencia', y='Sueldo Neto', data=df)\n",
    "plt.title('Boxplot de Sueldo Neto por Dependencia')\n",
    "plt.xlabel('Dependencia')\n",
    "plt.ylabel('Sueldo Neto')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.savefig('boxplot_dependencia.png')\n",
    "plt.close()\n",
    "\n",
    "# Gráficos de boxplot por tipo de dependencia\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.boxplot(x='Tipo', y='Sueldo Neto', data=df)\n",
    "plt.title('Boxplot de Sueldo Neto por Tipo de Dependencia')\n",
    "plt.xlabel('Tipo de Dependencia')\n",
    "plt.ylabel('Sueldo Neto')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.savefig('boxplot_tipo_dependencia.png')\n",
    "plt.close()\n",
    "\n",
    "# Gráficos de boxplot por año\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.boxplot(x='Año', y='Sueldo Neto', data=df)\n",
    "plt.title('Boxplot de Sueldo Neto por Año')\n",
    "plt.xlabel('Año')\n",
    "plt.ylabel('Sueldo Neto')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.savefig('boxplot_año.png')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503726cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dded7fcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae0e2ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d89ff2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Supongamos que el DataFrame df ya está cargado\n",
    "# df = pd.read_csv('csv/typed_itam.csv')\n",
    "# df['Fecha'] = pd.to_datetime(df['Fecha'])\n",
    "\n",
    "# Ordenar el DataFrame por fecha\n",
    "df = df.sort_values('Fecha')\n",
    "\n",
    "# Obtener las fechas únicas ordenadas\n",
    "fechas = df['Fecha'].drop_duplicates().sort_values()\n",
    "\n",
    "# Inicializar variables\n",
    "empleados_iniciales = df[df['Fecha'] == fechas.iloc[0]].groupby('dependencia')['Nombre'].apply(set).to_dict()\n",
    "empleados_previos = empleados_iniciales.copy()\n",
    "\n",
    "# Diccionarios para almacenar empleados nuevos, bajas y nuevas luego dadas de baja\n",
    "empleados_nuevos = {}\n",
    "empleados_bajas = {}\n",
    "empleados_nuevos_bajas = {}\n",
    "\n",
    "# Conjunto para almacenar todos los empleados nuevos\n",
    "todos_empleados_nuevos = {dep: set() for dep in empleados_iniciales.keys()}\n",
    "\n",
    "# Iterar sobre las fechas después del primer mes\n",
    "for fecha in fechas[1:]:\n",
    "    empleados_actuales = df[df['Fecha'] == fecha].groupby('dependencia')['Nombre'].apply(set).to_dict()\n",
    "    \n",
    "    for dep in empleados_actuales.keys():\n",
    "        if dep not in empleados_previos:\n",
    "            empleados_previos[dep] = set()\n",
    "            todos_empleados_nuevos[dep] = set()\n",
    "        \n",
    "        # Identificar nuevos empleados\n",
    "        nuevas = empleados_actuales[dep] - empleados_previos[dep]\n",
    "        if nuevas:\n",
    "            if dep not in empleados_nuevos:\n",
    "                empleados_nuevos[dep] = {}\n",
    "            empleados_nuevos[dep][fecha.strftime('%Y-%m')] = list(nuevas)\n",
    "            todos_empleados_nuevos[dep].update(nuevas)\n",
    "        \n",
    "        # Identificar empleados que dejaron de trabajar\n",
    "        bajas = empleados_previos[dep] - empleados_actuales[dep]\n",
    "        if bajas:\n",
    "            if dep not in empleados_bajas:\n",
    "                empleados_bajas[dep] = {}\n",
    "            empleados_bajas[dep][fecha.strftime('%Y-%m')] = list(bajas)\n",
    "    \n",
    "    # Actualizar el conjunto de empleados previos incluyendo las dependencias que no estuvieron en empleados_actuales\n",
    "    for dep in empleados_previos.keys():\n",
    "        if dep not in empleados_actuales:\n",
    "            if dep not in empleados_bajas:\n",
    "                empleados_bajas[dep] = {}\n",
    "            bajas = empleados_previos[dep]\n",
    "            if bajas:\n",
    "                empleados_bajas[dep][fecha.strftime('%Y-%m')] = list(bajas)\n",
    "\n",
    "    # Actualizar el conjunto de empleados previos\n",
    "    empleados_previos = empleados_actuales.copy()\n",
    "\n",
    "# Filtrar empleados que realmente dejaron de trabajar (considerando la última fecha)\n",
    "empleados_finales = df[df['Fecha'] == fechas.max()].groupby('dependencia')['Nombre'].apply(set).to_dict()\n",
    "empleados_bajas_reales = {\n",
    "    dep: {k: [emp for emp in v if dep in empleados_finales and emp not in empleados_finales[dep]] \n",
    "          for k, v in bajas.items()} \n",
    "    for dep, bajas in empleados_bajas.items()\n",
    "}\n",
    "\n",
    "# Identificar empleados nuevos que luego se dieron de baja\n",
    "for dep, bajas in empleados_bajas_reales.items():\n",
    "    for fecha, empleados in bajas.items():\n",
    "        nuevas_bajas = [emp for emp in empleados if dep in todos_empleados_nuevos and emp in todos_empleados_nuevos[dep]]\n",
    "        if nuevas_bajas:\n",
    "            if dep not in empleados_nuevos_bajas:\n",
    "                empleados_nuevos_bajas[dep] = {}\n",
    "            empleados_nuevos_bajas[dep][fecha] = nuevas_bajas\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(f\"Empleados nuevos por dependencia: {empleados_nuevos}\\n\\n\")\n",
    "print(f\"Empleados que dejaron de trabajar por dependencia: {empleados_bajas_reales}\\n\\n\")\n",
    "print(f\"Empleados nuevos por dependencia que luego se dieron de baja: {empleados_nuevos_bajas}\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a880635",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32efcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Supongamos que el DataFrame df ya está cargado\n",
    "# df = pd.read_csv('csv/typed_itam.csv')\n",
    "# df['Fecha'] = pd.to_datetime(df['Fecha'])\n",
    "\n",
    "# Filtrar los datos para el año 2023\n",
    "df_2023 = df[df['Fecha'].dt.year == 2023]\n",
    "\n",
    "# Agrupar por dependencia y empleado para sumar los sueldos netos\n",
    "sueldo_por_empleado = df_2023.groupby(['dependencia', 'Nombre'])['Sueldo Neto'].sum().reset_index()\n",
    "\n",
    "# Obtener el empleado con el sueldo neto más alto en cada dependencia\n",
    "empleado_top_por_dependencia = sueldo_por_empleado.loc[sueldo_por_empleado.groupby('dependencia')['Sueldo Neto'].idxmax()]\n",
    "\n",
    "# Ordenar los resultados de mayor a menor\n",
    "empleado_top_por_dependencia_ordenado = empleado_top_por_dependencia.sort_values(by='Sueldo Neto', ascending=False)\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(empleado_top_por_dependencia_ordenado)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c01fedd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea0e0f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf2669e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3cac89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1706aefa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8af26e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbb5f44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c5a8c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c567d05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49f8132",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5094cb76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8964b05a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd8ad42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "from typing import Tuple, List\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import shapiro, f_oneway, ttest_ind, kruskal\n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "\n",
    "\n",
    "def print_tabulate(df: pd.DataFrame):\n",
    "    print(tabulate(df, headers=df.columns, tablefmt='orgtbl'))\n",
    "\n",
    "\n",
    "def categorize(name:str)->str:\n",
    "    if 'PREPARATORIA' in name or 'PREPA.' in name:\n",
    "        return 'PREPARATORIA'\n",
    "    if 'FACULTAD' in name or 'FAC.' in name:\n",
    "        return 'FACULTAD'\n",
    "    if 'HOSPITAL' in name:\n",
    "        return 'HOSPITAL'\n",
    "    if 'CENTRO' in name or 'CTRO.' in name or 'C.' in name or 'INVESTIGAC' in name :\n",
    "        return 'CENTRO'\n",
    "    if 'SECRETARÍA' in name or 'SECRETARIA' in name or 'SRIA.' in name or 'DIRECCIÓN' in name or 'DIRECCION' in name or \\\n",
    "       'DEPARTAMENTO' in name or 'DEPTO.' in name or 'CONTRALORIA' in name or 'AUDITORIA' in name or 'TESORERIA' in name \\\n",
    "       or 'ESCOLAR' in name or 'ABOGACÍA' in name  or 'JUNTA' in name  or 'RECTORIA' in name  or 'IMAGEN' in name :\n",
    "        return 'ADMIN'\n",
    "    return 'OTRO'\n",
    "\n",
    "def transform_into_typed_df(raw_df: pd.DataFrame)->pd.DataFrame:\n",
    "    raw_df[\"Fecha\"] = pd.to_datetime(raw_df[\"anio\"].map(str)+ \"-\" + raw_df[\"mes\"].map(str), format=\"%Y-%m\")\n",
    "    raw_df = raw_df.drop(['anio', 'mes'], axis=1)\n",
    "    raw_df[\"Tipo\"] = raw_df[\"dependencia\"].map(categorize)\n",
    "    return raw_df\n",
    "\n",
    "\n",
    "\n",
    "def normalize_data(file_name:str) -> str:\n",
    "    df_complete = pd.read_csv(file_name)\n",
    "    df_complete[\"Fecha\"] = pd.to_datetime(df_complete[\"anio\"].map(str)+ \"-\" + df_complete[\"mes\"].map(str), format=\"%Y-%m\")\n",
    "    df_complete = df_complete.drop(['anio', 'mes'], axis=1)\n",
    "    df_complete[\"Tipo\"] = df_complete[\"dependencia\"].map(categorize)\n",
    "    df_complete.to_csv(\"csv/typed_uanl.csv\", index=False)\n",
    "    return \"csv/typed_uanl.csv\"\n",
    "\n",
    "def analysis_dependencia(file_name:str)->None:\n",
    "    df_complete = pd.read_csv(file_name)\n",
    "    df_complete[\"Fecha\"] = pd.to_datetime(df_complete[\"Fecha\"], format=\"%Y-%m-%d\")\n",
    "    df_complete[\"anio\"] = df_complete[\"Fecha\"].dt.year\n",
    "    # df_by_dep = df_complete.groupby([\"dependencia\", \"anio\"]).agg({'Sueldo Neto': ['sum', 'count']})\n",
    "    # print_tabulate(df_by_dep.head())\n",
    "    df_by_dep = df_complete.groupby([\"dependencia\", \"Fecha\"]).agg({'Sueldo Neto': ['sum', 'count', 'mean', 'min', 'max']})\n",
    "    df_by_dep = df_by_dep.reset_index()\n",
    "    print_tabulate(df_by_dep.head())\n",
    "    df_by_dep.to_csv(\"csv/uanl_dependencia_mes.csv\")\n",
    "\n",
    "\n",
    "def create_boxplot_by_type(file_name:str, column: str, agg_fn= pd.DataFrame.sum):\n",
    "    df_complete = pd.read_csv(file_name)\n",
    "    df_by_type = df_complete.groupby([column,\"Fecha\"])[[\"Sueldo Neto\"]].aggregate(agg_fn)# .count()\n",
    "    df_by_type.boxplot(by = column, figsize=(27,18))\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.savefig(f\"img2/boxplot_{column}.png\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_by_dep(df: pd.DataFrame, dep:str)->None:\n",
    "    df[df[\"dependencia\"] == dep].plot(y =[\"Sueldo Neto\"])\n",
    "    plt.savefig(f\"img2/lt_{dep}.png\")\n",
    "    df[df[\"dependencia\"] == dep].boxplot(by ='dependencia')\n",
    "    plt.savefig(f\"img2/bplt_{dep}.png\")\n",
    "\n",
    "\n",
    "def create_plot_por_dependencia(file_name:str):\n",
    "    df_complete = pd.read_csv(file_name)\n",
    "    df_by_dep = df_complete.groupby([\"dependencia\", \"Fecha\"])[[\"Sueldo Neto\"]].aggregate(pd.DataFrame.mean)\n",
    "    df_by_dep.reset_index(inplace=True)\n",
    "    df_by_dep.set_index(\"Fecha\", inplace=True)\n",
    "\n",
    "    for dep in set(df_by_dep[\"dependencia\"]):\n",
    "       plot_by_dep(df_by_dep, dep)\n",
    "    df_aux = df_complete.groupby([\"Fecha\",\"dependencia\"])[['Sueldo Neto']].mean().unstack()\n",
    "    df_aux.plot(y = 'Sueldo Neto', legend=False, figsize=(32,18))\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.savefig(\"img2/foo.png\")\n",
    "    plt.close()\n",
    "\n",
    "def anova(df_aux: pd.DataFrame, str_ols: str):\n",
    "    # shaphiro-wills\n",
    "    # Levenes or barletts\n",
    "    modl = ols(str_ols, data=df_aux).fit()\n",
    "    anova_df = sm.stats.anova_lm(modl, typ=2)\n",
    "    if anova_df[\"PR(>F)\"][0] < 0.005:\n",
    "        print(\"hay diferencias\")\n",
    "        print(anova_df)\n",
    "        # Prueba tukey\n",
    "        # imprimir los resultados\n",
    "    else:\n",
    "        print(\"No hay diferencias\")\n",
    "\n",
    "def anova_1(file_name: str):\n",
    "    df_complete = pd.read_csv(file_name)\n",
    "    df_by_type = df_complete.groupby([\"Tipo\", \"Fecha\"])[[\"Sueldo Neto\"]].aggregate(pd.DataFrame.sum)\n",
    "    df_by_type.reset_index(inplace=True)\n",
    "    df_by_type.set_index(\"Fecha\", inplace=True)\n",
    "    df_by_type.reset_index(inplace=True)\n",
    "    df_aux = df_by_type.rename(columns={\"Sueldo Neto\": \"GastoSalarios\"}).drop(['Fecha'], axis=1)\n",
    "    print(df_aux.head())\n",
    "    anova(df_aux, \"GastoSalarios ~ Tipo\")\n",
    "\n",
    "def analysis(file_name: str) -> None:\n",
    "    df_complete = pd.read_csv(file_name)\n",
    "    # print_tabulate(df_complete[[\"dependencia\",\"Tipo\"]].drop_duplicates().head(150))\n",
    "    df_by_dep = df_complete.groupby([\"dependencia\", \"Fecha\"])[[\"Sueldo Neto\"]].aggregate(pd.DataFrame.sum)\n",
    "\n",
    "    # df_by_dep_by_anio = df_by_dep.groupby([\"dependencia\",\"anio\"]).aggregate(pd.DataFrame.sum).sort_values(by=[\"dependencia\", \"anio\"], ascending=True)\n",
    "    df_by_dep.reset_index(inplace=True)\n",
    "    df_by_dep.set_index(\"Fecha\", inplace=True)\n",
    "    # print_tabulate(df_by_dep.head(5))\n",
    "\n",
    "    for dep in set(df_by_dep[\"dependencia\"]):\n",
    "        plot_by_dep(df_by_dep, dep)\n",
    "    \n",
    "    df_by_type = df_complete.groupby([\"Tipo\", \"Fecha\"])[[\"Sueldo Neto\"]].aggregate(pd.DataFrame.sum)\n",
    "    df_by_type.boxplot(by='Tipo', figsize=(18,9))\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.savefig(\"img2/boxplot_tipo.png\")\n",
    "    plt.close()\n",
    "\n",
    "    aux = df_complete.groupby([\"Tipo\"])[[\"Sueldo Neto\"]].aggregate(pd.DataFrame.sum)\n",
    "    aux.reset_index(inplace=True)\n",
    "    df_by_type.reset_index(inplace=True)\n",
    "    df_aux = df_by_type.rename(columns={\"Sueldo Neto\": \"GastoSalarios\"}).drop(['Fecha'], axis=1)\n",
    "    print(df_aux.head())\n",
    "\n",
    "    # Prueba ANOVA\n",
    "    modl = ols(\"GastoSalarios ~ Tipo\", data=df_aux).fit()\n",
    "    anova_df = sm.stats.anova_lm(modl, typ=2)\n",
    "    if anova_df[\"PR(>F)\"][0] < 0.005:\n",
    "        print(\"Hay diferencias\")\n",
    "        print(anova_df)\n",
    "        # Prueba Tukey\n",
    "        tukey_resultados = pairwise_tukeyhsd(df_aux['GastoSalarios'], df_aux['Tipo'])\n",
    "        print(tukey_resultados)\n",
    "    else:\n",
    "        print(\"No hay diferencias\")\n",
    "\n",
    "\n",
    "\n",
    "def create_typed_df(filename:str)-> pd.DataFrame:\n",
    "    df_complete = pd.read_csv(filename)\n",
    "    raw_df = transform_into_typed_df(df_complete)\n",
    "    print_tabulate(raw_df.head(50))\n",
    "    raw_df.to_csv(\"csv/typed_uanl.csv\", index=False)\n",
    "    return raw_df\n",
    "\n",
    "def show_type_of_department():\n",
    "    df_complete = pd.read_csv(\"csv/typed_uanl.csv\")\n",
    "    print_tabulate(df_complete[[\"dependencia\",\"Tipo\"]].\\\n",
    "                   drop_duplicates().head(150))\n",
    "\n",
    "def show_data_by_dependency_and_date():\n",
    "    df_complete = pd.read_csv(\"csv/typed_uanl.csv\")\n",
    "    df_by_dep = df_complete.groupby([\"dependencia\", \"Fecha\"])[[\"Sueldo Neto\"]].aggregate(pd.DataFrame.sum)\n",
    "    df_by_dep.reset_index(inplace=True)\n",
    "    df_by_dep.set_index(\"Fecha\", inplace=True)\n",
    "    print_tabulate(df_by_dep[df_by_dep[\"dependencia\"]== \"FAC. DE CIENCIAS FISICO-MATEMATICAS\"].head(50))\n",
    "\n",
    "\n",
    "def show_data_by_type_and_date():\n",
    "    df_complete = pd.read_csv(\"csv/typed_uanl.csv\")\n",
    "    df_by_type = df_complete.groupby([\"Tipo\", \"Fecha\"])[[\"Sueldo Neto\"]].aggregate(pd.DataFrame.sum)\n",
    "    df_by_type.reset_index(inplace=True)\n",
    "    df_by_type.set_index(\"Fecha\", inplace=True)\n",
    "    print_tabulate(df_by_type.head(150))\n",
    "\n",
    "\n",
    "def show_salary_and_count_by_type_and_date():\n",
    "    df_complete = pd.read_csv(\"csv/typed_uanl.csv\")\n",
    "    df_by_type = df_complete.groupby([\"Tipo\", \"Fecha\"]).agg({'Sueldo Neto': ['sum', 'count', 'mean', 'min']})\n",
    "    df_by_type.reset_index(inplace=True)\n",
    "    df_by_type.columns = ['Tipo', 'Fecha', 'Total_sueldos', 'Conteo_Empleado', 'Promedio_sueldo', 'Salario_Maximo']\n",
    "    df_by_type.set_index(\"Fecha\", inplace=True)\n",
    "    print_tabulate(df_by_type.head(150))\n",
    "\n",
    "def show_salary_and_count_by_dependency_and_date():\n",
    "    df_complete = pd.read_csv(\"csv/typed_uanl.csv\")\n",
    "    df_by_type = df_complete.groupby([\"dependencia\", \"Fecha\"]).agg({'Sueldo Neto': ['sum', 'count', 'mean', 'max']})\n",
    "    df_by_type.reset_index(inplace=True)\n",
    "    df_by_type.columns = ['Tipo', 'Fecha', 'Total_sueldos', 'Conteo_Empleado', 'Promedio_sueldo', 'Salario_Maximo']\n",
    "    df_by_type.set_index(\"Fecha\", inplace=True)\n",
    "    print_tabulate(df_by_type)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # analysis_dependencia(\"csv/typed_uanl.csv\")\n",
    "    # create_typed_df(\"csv/uanl.csv\")\n",
    "    # show_data_by_dependency_and_date()\n",
    "    # show_data_by_type_and_date()\n",
    "    # show_salary_and_count_by_type_and_date()\n",
    "    # show_salary_and_count_by_dependency_and_date()\n",
    "    \n",
    "    #### analysis(\"csv/typed_uanl.csv\")\n",
    "    \n",
    "    create_boxplot_by_type(\"csv/typed_uanl.csv\", 'dependencia', pd.DataFrame.mean)#\"Tipo\")\n",
    "    # create_plot_por_dependencia(\"csv/typed_uanl.csv\")\n",
    "    # anova_1(\"csv/typed_uanl.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0814ba0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
